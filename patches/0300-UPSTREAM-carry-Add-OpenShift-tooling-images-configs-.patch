From abc9e8b17e20d2063efdd520bd44a42a1045482b Mon Sep 17 00:00:00 2001
From: Fabio Bertinatto <fbertina@redhat.com>
Date: Wed, 22 Jan 2025 09:59:33 +0100
Subject: [PATCH] UPSTREAM: <carry>: Add OpenShift tooling, images, configs and
 docs

---
 .ci-operator.yaml                             |   2 +-
 .../openshift_payload_hyperkube.json          |   2 +-
 DOWNSTREAM_OWNERS                             |   4 +-
 build/pause/Dockerfile.Rhel                   |   2 +-
 hack/lib/golang.sh                            |   1 -
 .../cmd/k8s-tests-ext/disabled_tests.go       | 228 ++++++++++++++++
 .../k8s-tests-ext/environment_selectors.go    | 249 ++++++++++++++++++
 openshift-hack/cmd/k8s-tests-ext/k8s-tests.go |  63 ++++-
 openshift-hack/cmd/k8s-tests-ext/labels.go    |  52 ++++
 openshift-hack/cmd/k8s-tests/k8s-tests.go     |  98 -------
 openshift-hack/cmd/k8s-tests/provider.go      | 147 -----------
 openshift-hack/cmd/k8s-tests/runtest.go       | 143 ----------
 openshift-hack/cmd/k8s-tests/types.go         |  69 -----
 openshift-hack/e2e/annotate/rules.go          |  45 ++--
 openshift-hack/e2e/include.go                 |   1 -
 openshift-hack/e2e/kube_e2e_test.go           |  45 +++-
 .../images/hyperkube/Dockerfile.rhel          |   8 +-
 .../Dockerfile.rhel                           |  10 +-
 .../images/kube-proxy/Dockerfile.rhel         |   2 +-
 .../images/kube-proxy/test-kube-proxy.sh      |  14 +-
 openshift-hack/images/tests/Dockerfile.rhel   |   5 +-
 openshift-hack/test-kubernetes-e2e.sh         |   4 +-
 22 files changed, 675 insertions(+), 519 deletions(-)
 create mode 100644 openshift-hack/cmd/k8s-tests-ext/disabled_tests.go
 create mode 100644 openshift-hack/cmd/k8s-tests-ext/environment_selectors.go
 create mode 100644 openshift-hack/cmd/k8s-tests-ext/labels.go
 delete mode 100644 openshift-hack/cmd/k8s-tests/k8s-tests.go
 delete mode 100644 openshift-hack/cmd/k8s-tests/provider.go
 delete mode 100644 openshift-hack/cmd/k8s-tests/runtest.go
 delete mode 100644 openshift-hack/cmd/k8s-tests/types.go

diff --git a/.ci-operator.yaml b/.ci-operator.yaml
index 7c15f83e3e6..93022ee9763 100644
--- a/.ci-operator.yaml
+++ b/.ci-operator.yaml
@@ -1,4 +1,4 @@
 build_root_image:
   name: release
   namespace: openshift
-  tag: rhel-9-release-golang-1.23-openshift-4.19
+  tag: rhel-9-release-golang-1.24-nofips-openshift-4.19
diff --git a/.openshift-tests-extension/openshift_payload_hyperkube.json b/.openshift-tests-extension/openshift_payload_hyperkube.json
index 23e86487fa5..3bd71b79810 100644
--- a/.openshift-tests-extension/openshift_payload_hyperkube.json
+++ b/.openshift-tests-extension/openshift_payload_hyperkube.json
@@ -80076,4 +80076,4 @@
     "source": "openshift:payload:hyperkube",
     "lifecycle": "blocking"
   }
-]
\ No newline at end of file
+]
diff --git a/DOWNSTREAM_OWNERS b/DOWNSTREAM_OWNERS
index ad48a46ecdd..80caf1dc879 100644
--- a/DOWNSTREAM_OWNERS
+++ b/DOWNSTREAM_OWNERS
@@ -8,8 +8,8 @@ filters:
     - deads2k
     - jerpeter1
     - p0lyn0mial
-    - soltysh
     - tkashem
+    - benluddy
 
     # Approvers are limited to the team that manages rebases and pays the price for carries that are introduced
     approvers:
@@ -17,8 +17,8 @@ filters:
     - deads2k
     - jerpeter1
     - p0lyn0mial
-    - soltysh
     - tkashem
+    - benluddy
 
   "^\\.go.(mod|sum)$":
     labels:
diff --git a/build/pause/Dockerfile.Rhel b/build/pause/Dockerfile.Rhel
index 5dc852525b0..b16081a19ef 100644
--- a/build/pause/Dockerfile.Rhel
+++ b/build/pause/Dockerfile.Rhel
@@ -1,4 +1,4 @@
-FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.23-openshift-4.19 AS builder
+FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.24-nofips-openshift-4.19 AS builder
 WORKDIR /go/src/github.com/openshift/kubernetes/build/pause
 COPY . .
 RUN mkdir -p bin && \
diff --git a/hack/lib/golang.sh b/hack/lib/golang.sh
index d8485b53b88..898ce1c0c52 100755
--- a/hack/lib/golang.sh
+++ b/hack/lib/golang.sh
@@ -79,7 +79,6 @@ kube::golang::server_targets() {
     staging/src/k8s.io/apiextensions-apiserver
     cluster/gce/gci/mounter
     cmd/watch-termination
-    openshift-hack/cmd/k8s-tests
     openshift-hack/cmd/k8s-tests-ext
   )
   echo "${targets[@]}"
diff --git a/openshift-hack/cmd/k8s-tests-ext/disabled_tests.go b/openshift-hack/cmd/k8s-tests-ext/disabled_tests.go
new file mode 100644
index 00000000000..275cb62e76f
--- /dev/null
+++ b/openshift-hack/cmd/k8s-tests-ext/disabled_tests.go
@@ -0,0 +1,228 @@
+package main
+
+import (
+	et "github.com/openshift-eng/openshift-tests-extension/pkg/extension/extensiontests"
+	"k8s.io/apimachinery/pkg/util/sets"
+)
+
+// filterOutDisabledSpecs returns the specs with those that are disabled removed from the list
+func filterOutDisabledSpecs(specs et.ExtensionTestSpecs) et.ExtensionTestSpecs {
+	var disabledByReason = map[string][]string{
+		"Alpha": { // alpha features that are not gated
+			"[Feature:StorageVersionAPI]",
+			"[Feature:ClusterTrustBundle]",
+			"[Feature:SELinuxMount]",
+			"[FeatureGate:SELinuxMount]",
+			"[Feature:UserNamespacesPodSecurityStandards]",
+			"[Feature:DynamicResourceAllocation]",
+			"[Feature:VolumeAttributesClass]", // disabled Beta
+			"[sig-cli] Kubectl client Kubectl prune with applyset should apply and prune objects", // Alpha feature since k8s 1.27
+			// 4.19
+			"[Feature:PodLevelResources]",
+			"[Feature:PodLogsQuerySplitStreams]",
+			// 4.20
+			"[Feature:OffByDefault]",
+			"[Feature:CBOR]",
+		},
+		// tests for features that are not implemented in openshift
+		"Unimplemented": {
+			"Monitoring",                               // Not installed, should be
+			"Cluster level logging",                    // Not installed yet
+			"Kibana",                                   // Not installed
+			"Ubernetes",                                // Can't set zone labels today
+			"kube-ui",                                  // Not installed by default
+			"Kubernetes Dashboard",                     // Not installed by default (also probably slow image pull)
+			"should proxy to cadvisor",                 // we don't expose cAdvisor port directly for security reasons
+			"[Feature:BootstrapTokens]",                // we don't serve cluster-info configmap
+			"[Feature:KubeProxyDaemonSetMigration]",    // upgrades are run separately
+			"[Feature:BoundServiceAccountTokenVolume]", // upgrades are run separately
+			"[Feature:StatefulUpgrade]",                // upgrades are run separately
+		},
+		// tests that rely on special configuration that we do not yet support
+		"SpecialConfig": {
+			// GPU node needs to be available
+			"[Feature:GPUDevicePlugin]",
+			"[sig-scheduling] GPUDevicePluginAcrossRecreate [Feature:Recreate]",
+
+			"[Feature:LocalStorageCapacityIsolation]", // relies on a separate daemonset?
+			"[sig-cloud-provider-gcp]",                // these test require a different configuration - note that GCE tests from the sig-cluster-lifecycle were moved to the sig-cloud-provider-gcpcluster lifecycle see https://github.com/kubernetes/kubernetes/commit/0b3d50b6dccdc4bbd0b3e411c648b092477d79ac#diff-3b1910d08fb8fd8b32956b5e264f87cb
+
+			"kube-dns-autoscaler", // Don't run kube-dns
+			"should check if Kubernetes master services is included in cluster-info", // Don't run kube-dns
+			"DNS configMap", // this tests dns federation configuration via configmap, which we don't support yet
+
+			"NodeProblemDetector",                   // requires a non-master node to run on
+			"Advanced Audit should audit API calls", // expects to be able to call /logs
+
+			"Firewall rule should have correct firewall rules for e2e cluster", // Upstream-install specific
+
+			// https://bugzilla.redhat.com/show_bug.cgi?id=2079958
+			"[sig-network] [Feature:Topology Hints] should distribute endpoints evenly",
+
+			// Tests require SSH configuration and is part of the parallel suite, which does not create the bastion
+			// host. Enabling the test would result in the  bastion being created for every parallel test execution.
+			// Given that we have existing oc and WMCO tests that cover this functionality, we can safely disable it.
+			"[Feature:NodeLogQuery]",
+
+			// volumegroupsnapshot in csi-hostpath tests requires changes in the test yaml files,
+			// which are done by a script upstream. In OCP, we added a separate driver csi-hostpath-groupsnapshot,
+			// that will not be skipped by any rule here.
+			"[Driver: csi-hostpath] [Testpattern:  (delete policy)] volumegroupsnapshottable [Feature:volumegroupsnapshot]",
+		},
+		// tests that are known broken and need to be fixed upstream or in openshift
+		// always add an issue here
+		"Broken": {
+			"mount an API token into pods",                              // We add 6 secrets, not 1
+			"ServiceAccounts should ensure a single API token exists",   // We create lots of secrets
+			"unchanging, static URL paths for kubernetes api services",  // the test needs to exclude URLs that are not part of conformance (/logs)
+			"Services should be able to up and down services",           // we don't have wget installed on nodes
+			"KubeProxy should set TCP CLOSE_WAIT timeout",               // the test require communication to port 11302 in the cluster nodes
+			"should check kube-proxy urls",                              // previously this test was skipped b/c we reported -1 as the number of nodes, now we report proper number and test fails
+			"SSH",                                                       // TRIAGE
+			"should implement service.kubernetes.io/service-proxy-name", // this is an optional test that requires SSH. sig-network
+			"recreate nodes and ensure they function upon restart",      // https://bugzilla.redhat.com/show_bug.cgi?id=1756428
+			"[Driver: iscsi]",                                           // https://bugzilla.redhat.com/show_bug.cgi?id=1711627
+
+			"RuntimeClass should reject",
+
+			"Services should implement service.kubernetes.io/headless",                    // requires SSH access to function, needs to be refactored
+			"ClusterDns [Feature:Example] should create pod that uses dns",                // doesn't use bindata, not part of kube test binary
+			"Simple pod should return command exit codes should handle in-cluster config", // kubectl cp doesn't work or is not preserving executable bit, we have this test already
+
+			// TODO(node): configure the cri handler for the runtime class to make this work
+			"should run a Pod requesting a RuntimeClass with a configured handler",
+			"should reject a Pod requesting a RuntimeClass with conflicting node selector",
+			"should run a Pod requesting a RuntimeClass with scheduling",
+
+			// A fix is in progress: https://github.com/openshift/origin/pull/24709
+			"Multi-AZ Clusters should spread the pods of a replication controller across zones",
+
+			// Upstream assumes all control plane pods are in kube-system namespace and we should revert the change
+			// https://github.com/kubernetes/kubernetes/commit/176c8e219f4c7b4c15d34b92c50bfa5ba02b3aba#diff-28a3131f96324063dd53e17270d435a3b0b3bd8f806ee0e33295929570eab209R78
+			"MetricsGrabber should grab all metrics from a Kubelet",
+			"MetricsGrabber should grab all metrics from API server",
+			"MetricsGrabber should grab all metrics from a ControllerManager",
+			"MetricsGrabber should grab all metrics from a Scheduler",
+
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1906808
+			"ServiceAccounts should support OIDC discovery of service account issuer",
+
+			// NFS umount is broken in kernels 5.7+
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1854379
+			"[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted",
+
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1986306
+			"[sig-cli] Kubectl client kubectl wait should ignore not found error with --for=delete",
+
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1980141
+			"Netpol NetworkPolicy between server and client should enforce policy to allow traffic only from a pod in a different namespace based on PodSelector and NamespaceSelector",
+			"Netpol NetworkPolicy between server and client should enforce policy to allow traffic from pods within server namespace based on PodSelector",
+			"Netpol NetworkPolicy between server and client should enforce policy based on NamespaceSelector with MatchExpressions",
+			"Netpol NetworkPolicy between server and client should enforce policy based on PodSelector with MatchExpressions",
+			"Netpol NetworkPolicy between server and client should enforce policy based on PodSelector or NamespaceSelector",
+			"Netpol NetworkPolicy between server and client should deny ingress from pods on other namespaces",
+			"Netpol NetworkPolicy between server and client should enforce updated policy",
+			"Netpol NetworkPolicy between server and client should enforce multiple, stacked policies with overlapping podSelectors",
+			"Netpol NetworkPolicy between server and client should enforce policy based on any PodSelectors",
+			"Netpol NetworkPolicy between server and client should enforce policy to allow traffic only from a different namespace, based on NamespaceSelector",
+			"Netpol [LinuxOnly] NetworkPolicy between server and client using UDP should support a 'default-deny-ingress' policy",
+			"Netpol [LinuxOnly] NetworkPolicy between server and client using UDP should enforce policy based on Ports",
+			"Netpol [LinuxOnly] NetworkPolicy between server and client using UDP should enforce policy to allow traffic only from a pod in a different namespace based on PodSelector and NamespaceSelector",
+
+			"Topology Hints should distribute endpoints evenly",
+
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1908645
+			"[sig-network] Networking Granular Checks: Services should function for service endpoints using hostNetwork",
+			"[sig-network] Networking Granular Checks: Services should function for pod-Service(hostNetwork)",
+
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1952460
+			"[sig-network] Firewall rule control plane should not expose well-known ports",
+
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1988272
+			"[sig-network] Networking should provide Internet connection for containers [Feature:Networking-IPv6]",
+			"[sig-network] Networking should provider Internet connection for containers using DNS",
+
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1957894
+			"[sig-node] Container Runtime blackbox test when running a container with a new image should be able to pull from private registry with secret",
+
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1952457
+			"[sig-node] crictl should be able to run crictl on the node",
+
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1953478
+			"[sig-storage] Dynamic Provisioning Invalid AWS KMS key should report an error and create no PV",
+
+			// https://issues.redhat.com/browse/OCPBUGS-34577
+			"[sig-storage] Multi-AZ Cluster Volumes should schedule pods in the same zones as statically provisioned PVs",
+
+			// https://issues.redhat.com/browse/OCPBUGS-34594
+			"[sig-node] [Feature:PodLifecycleSleepAction] when create a pod with lifecycle hook using sleep action valid prestop hook using sleep action",
+
+			// https://issues.redhat.com/browse/OCPBUGS-38839
+			"[sig-network] Traffic Distribution",
+
+			// https://issues.redhat.com/browse/OCPBUGS-45273
+			"[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
+		},
+		// tests that need to be temporarily disabled while the rebase is in progress.
+		"RebaseInProgress": {
+			// https://issues.redhat.com/browse/OCPBUGS-7297
+			"DNS HostNetwork should resolve DNS of partial qualified names for services on hostNetwork pods with dnsPolicy",
+
+			// https://issues.redhat.com/browse/OCPBUGS-45275
+			"[sig-network] Connectivity Pod Lifecycle should be able to connect to other Pod from a terminating Pod",
+
+			// https://issues.redhat.com/browse/OCPBUGS-17194
+			"[sig-node] ImageCredentialProvider [Feature:KubeletCredentialProviders] should be able to create pod with image credentials fetched from external credential provider",
+
+			// Jan will look into this
+			// https://redhat-internal.slack.com/archives/C08KA82J2JF/p1743612984702079
+			"[Feature:SchedulerAsyncPreemption]",
+
+			// Requires flipping the gate in o/api after branch cut
+			// https://redhat-internal.slack.com/archives/C08KA82J2JF/p1743447032840259
+			"[Feature:UserNamespacesSupport]",
+
+			// Requires flipping the gate in o/api after branch cut
+			// https://redhat-internal.slack.com/archives/C08KA82J2JF/p1744285107158659?thread_ts=1743190159.388209&cid=C08KA82J2JF
+			"[FeatureGate:SELinuxChangePolicy]",
+		},
+		// tests that may work, but we don't support them
+		"Unsupported": {
+			"[Driver: rbd]",             // OpenShift 4.x does not support Ceph RBD (use CSI instead)
+			"[Driver: ceph]",            // OpenShift 4.x does not support CephFS (use CSI instead)
+			"[Driver: gluster]",         // OpenShift 4.x does not support Gluster
+			"Volumes GlusterFS",         // OpenShift 4.x does not support Gluster
+			"GlusterDynamicProvisioner", // OpenShift 4.x does not support Gluster
+
+			// Also, our CI doesn't support topology, so disable those tests
+			"[sig-storage] In-tree Volumes [Driver: vsphere] [Testpattern: Dynamic PV (delayed binding)] topology should fail to schedule a pod which has topologies that conflict with AllowedTopologies",
+			"[sig-storage] In-tree Volumes [Driver: vsphere] [Testpattern: Dynamic PV (delayed binding)] topology should provision a volume and schedule a pod with AllowedTopologies",
+			"[sig-storage] In-tree Volumes [Driver: vsphere] [Testpattern: Dynamic PV (immediate binding)] topology should fail to schedule a pod which has topologies that conflict with AllowedTopologies",
+			"[sig-storage] In-tree Volumes [Driver: vsphere] [Testpattern: Dynamic PV (immediate binding)] topology should provision a volume and schedule a pod with AllowedTopologies",
+		},
+	}
+
+	var disabledSpecs et.ExtensionTestSpecs
+	for _, disabledList := range disabledByReason {
+		var selectFunctions []et.SelectFunction
+		for _, disabledName := range disabledList {
+			selectFunctions = append(selectFunctions, et.NameContains(disabledName))
+		}
+
+		disabledSpecs = append(disabledSpecs, specs.SelectAny(selectFunctions)...)
+	}
+
+	disabledNames := sets.New[string]()
+	for _, disabledSpec := range disabledSpecs {
+		disabledNames.Insert(disabledSpec.Name)
+	}
+
+	enabledSpecs := specs[:0]
+	for _, spec := range specs {
+		if !disabledNames.Has(spec.Name) {
+			enabledSpecs = append(enabledSpecs, spec)
+		}
+	}
+
+	return enabledSpecs
+}
diff --git a/openshift-hack/cmd/k8s-tests-ext/environment_selectors.go b/openshift-hack/cmd/k8s-tests-ext/environment_selectors.go
new file mode 100644
index 00000000000..ea9070d1624
--- /dev/null
+++ b/openshift-hack/cmd/k8s-tests-ext/environment_selectors.go
@@ -0,0 +1,249 @@
+package main
+
+import (
+	"fmt"
+
+	et "github.com/openshift-eng/openshift-tests-extension/pkg/extension/extensiontests"
+)
+
+// addEnvironmentSelectors adds the environmentSelector field to appropriate specs to facilitate including or excluding
+// them based on attributes of the cluster they are running on
+func addEnvironmentSelectors(specs et.ExtensionTestSpecs) {
+	filterByPlatform(specs)
+	filterByExternalConnectivity(specs)
+	filterByTopology(specs)
+	filterByNoOptionalCapabilities(specs)
+	filterByNetwork(specs)
+
+	// LoadBalancer tests in 1.31 require explicit platform-specific skips
+	// https://issues.redhat.com/browse/OCPBUGS-38840
+	specs.SelectAny([]et.SelectFunction{ // Since these must use "NameContainsAll" they cannot be included in filterByPlatform
+		et.NameContainsAll("[sig-network] LoadBalancers [Feature:LoadBalancer]", "UDP"),
+		et.NameContainsAll("[sig-network] LoadBalancers [Feature:LoadBalancer]", "session affinity"),
+	}).Exclude(et.PlatformEquals("aws")).AddLabel("[Skipped:aws]")
+
+	specs.SelectAny([]et.SelectFunction{ // Since these must use "NameContainsAll" they cannot be included in filterByNetwork
+		et.NameContainsAll("NetworkPolicy", "named port"),
+	}).Exclude(et.NetworkEquals("OVNKubernetes")).AddLabel("[Skipped:Network/OVNKubernetes]")
+}
+
+// filterByPlatform is a helper function to do, simple, "NameContains" filtering on tests by platform
+func filterByPlatform(specs et.ExtensionTestSpecs) {
+	var platformExclusions = map[string][]string{
+		"alibabacloud": {
+			// LoadBalancer tests in 1.31 require explicit platform-specific skips
+			// https://issues.redhat.com/browse/OCPBUGS-38840
+			"[Feature:LoadBalancer]",
+		},
+		"azure": {
+			"Networking should provide Internet connection for containers", // Azure does not allow ICMP traffic to internet.
+			// Azure CSI migration changed how we treat regions without zones.
+			// See https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=2066865
+			"[sig-storage] In-tree Volumes [Driver: azure-disk] [Testpattern: Dynamic PV (immediate binding)] topology should provision a volume and schedule a pod with AllowedTopologies",
+			"[sig-storage] In-tree Volumes [Driver: azure-disk] [Testpattern: Dynamic PV (delayed binding)] topology should provision a volume and schedule a pod with AllowedTopologies",
+		},
+		"baremetal": {
+			// LoadBalancer tests in 1.31 require explicit platform-specific skips
+			// https://issues.redhat.com/browse/OCPBUGS-38840
+			"[Feature:LoadBalancer]",
+		},
+		"gce": {
+			// Requires creation of a different compute instance in a different zone and is not compatible with volumeBindingMode of WaitForFirstConsumer which we use in 4.x
+			"[sig-storage] Multi-AZ Cluster Volumes should only be allowed to provision PDs in zones where nodes exist",
+			// The following tests try to ssh directly to a node. None of our nodes have external IPs
+			"[k8s.io] [sig-node] crictl should be able to run crictl on the node",
+			"[sig-storage] Flexvolumes should be mountable",
+			"[sig-storage] Detaching volumes should not work when mount is in progress",
+			// We are using ovn-kubernetes to conceal metadata
+			"[sig-auth] Metadata Concealment should run a check-metadata-concealment job to completion",
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1740959
+			"[sig-api-machinery] AdmissionWebhook should be able to deny pod and configmap creation",
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1745720
+			"[sig-storage] CSI Volumes [Driver: pd.csi.storage.gke.io]",
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1749882
+			"[sig-storage] CSI Volumes CSI Topology test using GCE PD driver [Serial]",
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1751367
+			"gce-localssd-scsi-fs",
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1750851
+			// should be serial if/when it's re-enabled
+			"[HPA] Horizontal pod autoscaling (scale resource: Custom Metrics from Stackdriver)",
+			"[Feature:CustomMetricsAutoscaling]",
+		},
+		"ibmcloud": {
+			// LoadBalancer tests in 1.31 require explicit platform-specific skips
+			// https://issues.redhat.com/browse/OCPBUGS-38840
+			"[Feature:LoadBalancer]",
+		},
+		"ibmroks": {
+			// Calico is allowing the request to timeout instead of returning 'REFUSED'
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1825021 - ROKS: calico SDN results in a request timeout when accessing services with no endpoints
+			"[sig-network] Services should be rejected when no endpoints exist",
+			// Nodes in ROKS have access to secrets in the cluster to handle encryption
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1825013 - ROKS: worker nodes have access to secrets in the cluster
+			"[sig-auth] [Feature:NodeAuthorizer] Getting a non-existent configmap should exit with the Forbidden error, not a NotFound error",
+			"[sig-auth] [Feature:NodeAuthorizer] Getting a non-existent secret should exit with the Forbidden error, not a NotFound error",
+			"[sig-auth] [Feature:NodeAuthorizer] Getting a secret for a workload the node has access to should succeed",
+			"[sig-auth] [Feature:NodeAuthorizer] Getting an existing configmap should exit with the Forbidden error",
+			"[sig-auth] [Feature:NodeAuthorizer] Getting an existing secret should exit with the Forbidden error",
+			// Access to node external address is blocked from pods within a ROKS cluster by Calico
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1825016 - e2e: NodeAuthenticator tests use both external and internal addresses for node
+			"[sig-auth] [Feature:NodeAuthenticator] The kubelet's main port 10250 should reject requests with no credentials",
+			"[sig-auth] [Feature:NodeAuthenticator] The kubelet can delegate ServiceAccount tokens to the API server",
+			// Mode returned by RHEL7 worker contains an extra character not expected by the test: dgtrwx vs dtrwx
+			// https://bugzilla.redhat.com/show_bug.cgi?id=1825024 - e2e: Failing test - HostPath should give a volume the correct mode
+			"[sig-storage] HostPath should give a volume the correct mode",
+		},
+		"kubevirt": {
+			// LoadBalancer tests in 1.31 require explicit platform-specific skips
+			// https://issues.redhat.com/browse/OCPBUGS-38840
+			"[Feature:LoadBalancer]",
+		},
+		"nutanix": {
+			// LoadBalancer tests in 1.31 require explicit platform-specific skips
+			// https://issues.redhat.com/browse/OCPBUGS-38840
+			"[Feature:LoadBalancer]",
+		},
+		"openstack": {
+			// LoadBalancer tests in 1.31 require explicit platform-specific skips
+			// https://issues.redhat.com/browse/OCPBUGS-38840
+			"[Feature:LoadBalancer]",
+		},
+		"ovirt": {
+			// LoadBalancer tests in 1.31 require explicit platform-specific skips
+			// https://issues.redhat.com/browse/OCPBUGS-38840
+			"[Feature:LoadBalancer]",
+		},
+		"vsphere": {
+			// LoadBalancer tests in 1.31 require explicit platform-specific skips
+			// https://issues.redhat.com/browse/OCPBUGS-38840
+			"[Feature:LoadBalancer]",
+		},
+		"external": {
+			// LoadBalancer tests in 1.31 require explicit platform-specific skips
+			// https://issues.redhat.com/browse/OCPBUGS-53249
+			"[sig-network] LoadBalancers [Feature:LoadBalancer] should be able to preserve UDP traffic when server pod cycles for a LoadBalancer service on",
+		},
+	}
+
+	for platform, exclusions := range platformExclusions {
+		var selectFunctions []et.SelectFunction
+		for _, exclusion := range exclusions {
+			selectFunctions = append(selectFunctions, et.NameContains(exclusion))
+		}
+
+		specs.SelectAny(selectFunctions).
+			Exclude(et.PlatformEquals(platform)).
+			AddLabel(fmt.Sprintf("[Skipped:%s]", platform))
+	}
+}
+
+// filterByExternalConnectivity is a helper function to do, simple, "NameContains" filtering on tests by external connectivity
+func filterByExternalConnectivity(specs et.ExtensionTestSpecs) {
+	var externalConnectivityExclusions = map[string][]string{
+		// Tests that don't pass on disconnected, either due to requiring
+		// internet access for GitHub (e.g. many of the s2i builds), or
+		// because of pullthrough not supporting ICSP (https://bugzilla.redhat.com/show_bug.cgi?id=1918376)
+		"Disconnected": {
+			"[sig-network] Networking should provide Internet connection for containers",
+		},
+		// These tests are skipped when openshift-tests needs to use a proxy to reach the
+		// cluster -- either because the test won't work while proxied, or because the test
+		// itself is testing a functionality using it's own proxy.
+		"Proxy": {
+			// These tests setup their own proxy, which won't work when we need to access the
+			// cluster through a proxy.
+			"[sig-cli] Kubectl client Simple pod should support exec through an HTTP proxy",
+			"[sig-cli] Kubectl client Simple pod should support exec through kubectl proxy",
+			// Kube currently uses the x/net/websockets pkg, which doesn't work with proxies.
+			// See: https://github.com/kubernetes/kubernetes/pull/103595
+			"[sig-node] Pods should support retrieving logs from the container over websockets",
+			"[sig-cli] Kubectl Port forwarding With a server listening on localhost should support forwarding over websockets",
+			"[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 should support forwarding over websockets",
+			"[sig-node] Pods should support remote command execution over websockets",
+			// These tests are flacky and require internet access
+			// See https://bugzilla.redhat.com/show_bug.cgi?id=2019375
+			"[sig-network] DNS should resolve DNS of partial qualified names for services",
+			"[sig-network] DNS should provide DNS for the cluster",
+			// This test does not work when using in-proxy cluster, see https://bugzilla.redhat.com/show_bug.cgi?id=2084560
+			"[sig-network] Networking should provide Internet connection for containers",
+		},
+	}
+
+	for externalConnectivity, exclusions := range externalConnectivityExclusions {
+		var selectFunctions []et.SelectFunction
+		for _, exclusion := range exclusions {
+			selectFunctions = append(selectFunctions, et.NameContains(exclusion))
+		}
+
+		specs.SelectAny(selectFunctions).
+			Exclude(et.ExternalConnectivityEquals(externalConnectivity)).
+			AddLabel(fmt.Sprintf("[Skipped:%s]", externalConnectivity))
+	}
+}
+
+// filterByTopology is a helper function to do, simple, "NameContains" filtering on tests by topology
+func filterByTopology(specs et.ExtensionTestSpecs) {
+	var topologyExclusions = map[string][]string{
+		"SingleReplicaTopology": {
+			"[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]",
+			"[sig-node] NoExecuteTaintManager Single Pod [Serial] doesn't evict pod with tolerations from tainted nodes",
+			"[sig-node] NoExecuteTaintManager Single Pod [Serial] eventually evict pod with finite tolerations from tainted nodes",
+			"[sig-node] NoExecuteTaintManager Single Pod [Serial] evicts pods from tainted nodes",
+			"[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]",
+			"[sig-node] NoExecuteTaintManager Single Pod [Serial] pods evicted from tainted nodes have pod disruption condition",
+			"[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]",
+			"[sig-node] NoExecuteTaintManager Multiple Pods [Serial] only evicts pods without tolerations from tainted nodes",
+			"[sig-cli] Kubectl client Kubectl taint [Serial] should remove all the taints with the same key off a node",
+			"[sig-network] LoadBalancers should be able to preserve UDP traffic when server pod cycles for a LoadBalancer service on different nodes",
+			"[sig-network] LoadBalancers should be able to preserve UDP traffic when server pod cycles for a LoadBalancer service on the same nodes",
+			"[sig-architecture] Conformance Tests should have at least two untainted nodes",
+		},
+	}
+
+	for topology, exclusions := range topologyExclusions {
+		var selectFunctions []et.SelectFunction
+		for _, exclusion := range exclusions {
+			selectFunctions = append(selectFunctions, et.NameContains(exclusion))
+		}
+
+		specs.SelectAny(selectFunctions).
+			Exclude(et.TopologyEquals(topology)).
+			AddLabel(fmt.Sprintf("[Skipped:%s]", topology))
+	}
+}
+
+// filterByNoOptionalCapabilities is a helper function to facilitate adding environment selectors for tests which can't
+// be run/don't make sense to run against a cluster with all optional capabilities disabled
+func filterByNoOptionalCapabilities(specs et.ExtensionTestSpecs) {
+	var exclusions = []string{
+		// Requires CSISnapshot capability
+		"[Feature:VolumeSnapshotDataSource]",
+		// Requires Storage capability
+		"[Driver: aws]",
+		"[Feature:StorageProvider]",
+	}
+
+	var selectFunctions []et.SelectFunction
+	for _, exclusion := range exclusions {
+		selectFunctions = append(selectFunctions, et.NameContains(exclusion))
+	}
+	specs.SelectAny(selectFunctions).
+		Exclude(et.NoOptionalCapabilitiesExist()).
+		AddLabel("[Skipped:NoOptionalCapabilities]")
+}
+
+// filterByNetwork is a helper function to do, simple, "NameContains" filtering on tests by network
+func filterByNetwork(specs et.ExtensionTestSpecs) {
+	var networkExclusions = map[string][]string{}
+
+	for network, exclusions := range networkExclusions {
+		var selectFunctions []et.SelectFunction
+		for _, exclusion := range exclusions {
+			selectFunctions = append(selectFunctions, et.NameContains(exclusion))
+		}
+
+		specs.SelectAny(selectFunctions).
+			Exclude(et.NetworkEquals(network)).
+			AddLabel(fmt.Sprintf("[Skipped:%s]", network))
+	}
+}
diff --git a/openshift-hack/cmd/k8s-tests-ext/k8s-tests.go b/openshift-hack/cmd/k8s-tests-ext/k8s-tests.go
index 03b626a827a..03dd0b7a661 100644
--- a/openshift-hack/cmd/k8s-tests-ext/k8s-tests.go
+++ b/openshift-hack/cmd/k8s-tests-ext/k8s-tests.go
@@ -2,22 +2,26 @@ package main
 
 import (
 	"flag"
-	"k8s.io/kubernetes/test/e2e/framework"
 	"os"
+	"reflect"
+	"strconv"
+
+	et "github.com/openshift-eng/openshift-tests-extension/pkg/extension/extensiontests"
+	"k8s.io/kubernetes/openshift-hack/e2e/annotate/generated"
+	"k8s.io/kubernetes/test/e2e/framework"
 
 	"github.com/spf13/cobra"
 	"github.com/spf13/pflag"
 
 	"github.com/openshift-eng/openshift-tests-extension/pkg/cmd"
 	e "github.com/openshift-eng/openshift-tests-extension/pkg/extension"
-	"github.com/openshift-eng/openshift-tests-extension/pkg/extension/extensiontests"
 	g "github.com/openshift-eng/openshift-tests-extension/pkg/ginkgo"
 	v "github.com/openshift-eng/openshift-tests-extension/pkg/version"
 
 	"k8s.io/client-go/pkg/version"
 	utilflag "k8s.io/component-base/cli/flag"
 	"k8s.io/component-base/logs"
-	"k8s.io/kubernetes/openshift-hack/e2e/annotate/generated"
+	"k8s.io/kubernetes/test/utils/image"
 
 	// initialize framework extensions
 	_ "k8s.io/kubernetes/test/e2e/framework/debug/init"
@@ -64,6 +68,12 @@ func main() {
 		Qualifiers: []string{`labels.exists(l, l == "Serial") && labels.exists(l, l == "Conformance")`},
 	})
 
+	for k, v := range image.GetOriginalImageConfigs() {
+		image := convertToImage(v)
+		image.Index = int(k)
+		kubeTestsExtension.RegisterImage(image)
+	}
+
 	//FIXME(stbenjam): what other suites does k8s-test contribute to?
 
 	// Build our specs from ginkgo
@@ -87,11 +97,28 @@ func main() {
 	//		  the environmental skip code from the enhancement once its implemented.
 	//		- Make sure to account for test renames that occur because of removal of these
 	//		  annotations
-	specs.Walk(func(spec *extensiontests.ExtensionTestSpec) {
-		if annotations, ok := generated.Annotations[spec.Name]; ok {
-			spec.Name += annotations
+	var omitAnnotations bool
+	omitAnnotationsVal := os.Getenv("OMIT_ANNOTATIONS")
+	if omitAnnotationsVal != "" {
+		omitAnnotations, err = strconv.ParseBool(omitAnnotationsVal)
+		if err != nil {
+			panic("Failed to parse OMIT_ANNOTATIONS: " + err.Error())
 		}
-	})
+	}
+	if !omitAnnotations {
+		specs.Walk(func(spec *et.ExtensionTestSpec) {
+			if annotations, ok := generated.Annotations[spec.Name]; ok {
+				spec.Name += annotations
+			}
+		})
+	}
+
+	specs = filterOutDisabledSpecs(specs)
+	addLabelsToSpecs(specs)
+
+	// EnvironmentSelectors added to the appropriate specs to facilitate including or excluding them
+	// based on attributes of the cluster they are running on
+	addEnvironmentSelectors(specs)
 
 	kubeTestsExtension.AddSpecs(specs)
 
@@ -110,3 +137,25 @@ func main() {
 		os.Exit(1)
 	}
 }
+
+// convertToImages converts an image.Config to an extension.Image, which
+// can easily be serialized to JSON. Since image.Config has unexported fields,
+// reflection is used to read its values.
+func convertToImage(obj interface{}) e.Image {
+	image := e.Image{}
+	val := reflect.ValueOf(obj)
+	typ := reflect.TypeOf(obj)
+	for i := 0; i < val.NumField(); i++ {
+		structField := typ.Field(i)
+		fieldValue := val.Field(i)
+		switch structField.Name {
+		case "registry":
+			image.Registry = fieldValue.String()
+		case "name":
+			image.Name = fieldValue.String()
+		case "version":
+			image.Version = fieldValue.String()
+		}
+	}
+	return image
+}
diff --git a/openshift-hack/cmd/k8s-tests-ext/labels.go b/openshift-hack/cmd/k8s-tests-ext/labels.go
new file mode 100644
index 00000000000..997937706cc
--- /dev/null
+++ b/openshift-hack/cmd/k8s-tests-ext/labels.go
@@ -0,0 +1,52 @@
+package main
+
+import (
+	et "github.com/openshift-eng/openshift-tests-extension/pkg/extension/extensiontests"
+)
+
+func addLabelsToSpecs(specs et.ExtensionTestSpecs) {
+	var namesByLabel = map[string][]string{
+		// tests too slow to be part of conformance
+		"[Slow]": {
+			"[sig-scalability]",                            // disable from the default set for now
+			"should create and stop a working application", // Inordinately slow tests
+
+			"[Feature:PerformanceDNS]", // very slow
+
+			"validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP", // 5m, really?
+		},
+		// tests that are known flaky
+		"[Flaky]": {
+			"Job should run a job to completion when tasks sometimes fail and are not locally restarted", // seems flaky, also may require too many resources
+			// TODO(node): test works when run alone, but not in the suite in CI
+			"[Feature:HPA] Horizontal pod autoscaling (scale resource: CPU) [sig-autoscaling] ReplicationController light Should scale from 1 pod to 2 pods",
+		},
+		// tests that must be run without competition
+		"[Serial]": {
+			"[Disruptive]",
+			"[Feature:Performance]", // requires isolation
+
+			"Service endpoints latency", // requires low latency
+			"Clean up pods on node",     // schedules up to max pods per node
+			"DynamicProvisioner should test that deleting a claim before the volume is provisioned deletes the volume", // test is very disruptive to other tests
+
+			"Should be able to support the 1.7 Sample API Server using the current Aggregator", // down apiservices break other clients today https://bugzilla.redhat.com/show_bug.cgi?id=1623195
+
+			"[Feature:HPA] Horizontal pod autoscaling (scale resource: CPU) [sig-autoscaling] ReplicationController light Should scale from 1 pod to 2 pods",
+
+			"should prevent Ingress creation if more than 1 IngressClass marked as default", // https://bugzilla.redhat.com/show_bug.cgi?id=1822286
+
+			"[sig-network] IngressClass [Feature:Ingress] should set default value on new IngressClass", //https://bugzilla.redhat.com/show_bug.cgi?id=1833583
+		},
+	}
+
+	for label, names := range namesByLabel {
+		var selectFunctions []et.SelectFunction
+		for _, name := range names {
+			selectFunctions = append(selectFunctions, et.NameContains(name))
+		}
+
+		//TODO: once annotation logic has been removed, it might also be necessary to annotate the test name with the label as well
+		specs.SelectAny(selectFunctions).AddLabel(label)
+	}
+}
diff --git a/openshift-hack/cmd/k8s-tests/k8s-tests.go b/openshift-hack/cmd/k8s-tests/k8s-tests.go
deleted file mode 100644
index fedd8b16f01..00000000000
--- a/openshift-hack/cmd/k8s-tests/k8s-tests.go
+++ /dev/null
@@ -1,98 +0,0 @@
-package main
-
-import (
-	"encoding/json"
-	"flag"
-	"fmt"
-	"math/rand"
-	"os"
-	"sort"
-	"time"
-
-	"github.com/spf13/cobra"
-	"github.com/spf13/pflag"
-
-	utilflag "k8s.io/component-base/cli/flag"
-	"k8s.io/component-base/logs"
-	"k8s.io/kubernetes/test/e2e/framework"
-
-	// initialize framework extensions
-	_ "k8s.io/kubernetes/test/e2e/framework/debug/init"
-	_ "k8s.io/kubernetes/test/e2e/framework/metrics/init"
-)
-
-func main() {
-	logs.InitLogs()
-	defer logs.FlushLogs()
-
-	rand.Seed(time.Now().UTC().UnixNano())
-
-	pflag.CommandLine.SetNormalizeFunc(utilflag.WordSepNormalizeFunc)
-
-	root := &cobra.Command{
-		Long: "OpenShift Tests compatible wrapper",
-	}
-
-	root.AddCommand(
-		newRunTestCommand(),
-		newListTestsCommand(),
-	)
-
-	f := flag.CommandLine.Lookup("v")
-	root.PersistentFlags().AddGoFlag(f)
-	pflag.CommandLine = pflag.NewFlagSet("empty", pflag.ExitOnError)
-	flag.CommandLine = flag.NewFlagSet("empty", flag.ExitOnError)
-	framework.RegisterCommonFlags(flag.CommandLine)
-	framework.RegisterClusterFlags(flag.CommandLine)
-
-	if err := func() error {
-		return root.Execute()
-	}(); err != nil {
-		if ex, ok := err.(ExitError); ok {
-			fmt.Fprintf(os.Stderr, "Ginkgo exit error %d: %v\n", ex.Code, err)
-			os.Exit(ex.Code)
-		}
-		fmt.Fprintf(os.Stderr, "error: %v\n", err)
-		os.Exit(1)
-	}
-}
-
-func newRunTestCommand() *cobra.Command {
-	testOpt := NewTestOptions(os.Stdout, os.Stderr)
-
-	cmd := &cobra.Command{
-		Use:          "run-test NAME",
-		Short:        "Run a single test by name",
-		Long:         "Execute a single test.",
-		SilenceUsage: true,
-		RunE: func(cmd *cobra.Command, args []string) error {
-			if err := initializeTestFramework(os.Getenv("TEST_PROVIDER")); err != nil {
-				return err
-			}
-
-			return testOpt.Run(args)
-		},
-	}
-	return cmd
-}
-
-func newListTestsCommand() *cobra.Command {
-	cmd := &cobra.Command{
-		Use:          "list",
-		Short:        "List available tests",
-		Long:         "List the available tests in this binary.",
-		SilenceUsage: true,
-		RunE: func(cmd *cobra.Command, args []string) error {
-			tests := testsForSuite()
-			sort.Slice(tests, func(i, j int) bool { return tests[i].Name < tests[j].Name })
-			data, err := json.Marshal(tests)
-			if err != nil {
-				return err
-			}
-			fmt.Fprintf(os.Stdout, "%s\n", data)
-			return nil
-		},
-	}
-
-	return cmd
-}
diff --git a/openshift-hack/cmd/k8s-tests/provider.go b/openshift-hack/cmd/k8s-tests/provider.go
deleted file mode 100644
index cdc948a45c6..00000000000
--- a/openshift-hack/cmd/k8s-tests/provider.go
+++ /dev/null
@@ -1,147 +0,0 @@
-package main
-
-import (
-	"context"
-	"encoding/json"
-	"fmt"
-	"os"
-	"path/filepath"
-	"strings"
-
-	"github.com/onsi/ginkgo/v2"
-	"github.com/onsi/gomega"
-
-	corev1 "k8s.io/api/core/v1"
-	kclientset "k8s.io/client-go/kubernetes"
-	"k8s.io/client-go/tools/clientcmd"
-	"k8s.io/kubernetes/openshift-hack/e2e"
-	conformancetestdata "k8s.io/kubernetes/test/conformance/testdata"
-	"k8s.io/kubernetes/test/e2e/framework"
-	"k8s.io/kubernetes/test/e2e/framework/testfiles"
-	"k8s.io/kubernetes/test/e2e/storage/external"
-	e2etestingmanifests "k8s.io/kubernetes/test/e2e/testing-manifests"
-	testfixtures "k8s.io/kubernetes/test/fixtures"
-
-	// this appears to inexplicably auto-register global flags.
-	_ "k8s.io/kubernetes/test/e2e/storage/drivers"
-
-	// these are loading important global flags that we need to get and set
-	_ "k8s.io/kubernetes/test/e2e"
-	_ "k8s.io/kubernetes/test/e2e/lifecycle"
-)
-
-// copied directly from github.com/openshift/origin/cmd/openshift-tests/provider.go
-// and github.com/openshift/origin/test/extended/util/test.go
-func initializeTestFramework(provider string) error {
-	providerInfo := &ClusterConfiguration{}
-	if err := json.Unmarshal([]byte(provider), &providerInfo); err != nil {
-		return fmt.Errorf("provider must be a JSON object with the 'type' key at a minimum: %v", err)
-	}
-	if len(providerInfo.ProviderName) == 0 {
-		return fmt.Errorf("provider must be a JSON object with the 'type' key")
-	}
-	config := &ClusterConfiguration{}
-	if err := json.Unmarshal([]byte(provider), config); err != nil {
-		return fmt.Errorf("provider must decode into the ClusterConfig object: %v", err)
-	}
-
-	// update testContext with loaded config
-	testContext := &framework.TestContext
-	testContext.Provider = config.ProviderName
-	testContext.CloudConfig = framework.CloudConfig{
-		ProjectID:   config.ProjectID,
-		Region:      config.Region,
-		Zone:        config.Zone,
-		Zones:       config.Zones,
-		NumNodes:    config.NumNodes,
-		MultiMaster: config.MultiMaster,
-		MultiZone:   config.MultiZone,
-		ConfigFile:  config.ConfigFile,
-	}
-	testContext.AllowedNotReadyNodes = -1
-	testContext.MinStartupPods = -1
-	testContext.MaxNodesToGather = 0
-	testContext.KubeConfig = os.Getenv("KUBECONFIG")
-
-	// allow the CSI tests to access test data, but only briefly
-	// TODO: ideally CSI would not use any of these test methods
-	// var err error
-	// exutil.WithCleanup(func() { err = initCSITests(dryRun) })
-	// TODO: for now I'm only initializing CSI directly, but we probably need that
-	// WithCleanup here as well
-	if err := initCSITests(); err != nil {
-		return err
-	}
-
-	if ad := os.Getenv("ARTIFACT_DIR"); len(strings.TrimSpace(ad)) == 0 {
-		os.Setenv("ARTIFACT_DIR", filepath.Join(os.TempDir(), "artifacts"))
-	}
-
-	testContext.DeleteNamespace = os.Getenv("DELETE_NAMESPACE") != "false"
-	testContext.VerifyServiceAccount = true
-	testfiles.AddFileSource(e2etestingmanifests.GetE2ETestingManifestsFS())
-	testfiles.AddFileSource(testfixtures.GetTestFixturesFS())
-	testfiles.AddFileSource(conformancetestdata.GetConformanceTestdataFS())
-	testContext.KubectlPath = "kubectl"
-	// context.KubeConfig = KubeConfigPath()
-	testContext.KubeConfig = os.Getenv("KUBECONFIG")
-
-	// "debian" is used when not set. At least GlusterFS tests need "custom".
-	// (There is no option for "rhel" or "centos".)
-	testContext.NodeOSDistro = "custom"
-	testContext.MasterOSDistro = "custom"
-
-	// load and set the host variable for kubectl
-	clientConfig := clientcmd.NewNonInteractiveDeferredLoadingClientConfig(&clientcmd.ClientConfigLoadingRules{ExplicitPath: testContext.KubeConfig}, &clientcmd.ConfigOverrides{})
-	cfg, err := clientConfig.ClientConfig()
-	if err != nil {
-		return err
-	}
-	testContext.Host = cfg.Host
-
-	// Ensure that Kube tests run privileged (like they do upstream)
-	testContext.CreateTestingNS = func(ctx context.Context, baseName string, c kclientset.Interface, labels map[string]string) (*corev1.Namespace, error) {
-		return e2e.CreateTestingNS(ctx, baseName, c, labels, true)
-	}
-
-	gomega.RegisterFailHandler(ginkgo.Fail)
-
-	framework.AfterReadingAllFlags(testContext)
-	testContext.DumpLogsOnFailure = true
-
-	// these constants are taken from kube e2e and used by tests
-	testContext.IPFamily = "ipv4"
-	if config.HasIPv6 && !config.HasIPv4 {
-		testContext.IPFamily = "ipv6"
-	}
-
-	testContext.ReportDir = os.Getenv("TEST_JUNIT_DIR")
-
-	return nil
-}
-
-const (
-	manifestEnvVar = "TEST_CSI_DRIVER_FILES"
-)
-
-// copied directly from github.com/openshift/origin/cmd/openshift-tests/csi.go
-// Initialize openshift/csi suite, i.e. define CSI tests from TEST_CSI_DRIVER_FILES.
-func initCSITests() error {
-	manifestList := os.Getenv(manifestEnvVar)
-	if manifestList != "" {
-		manifests := strings.Split(manifestList, ",")
-		for _, manifest := range manifests {
-			if err := external.AddDriverDefinition(manifest); err != nil {
-				return fmt.Errorf("failed to load manifest from %q: %s", manifest, err)
-			}
-			// Register the base dir of the manifest file as a file source.
-			// With this we can reference the CSI driver's storageClass
-			// in the manifest file (FromFile field).
-			testfiles.AddFileSource(testfiles.RootFileSource{
-				Root: filepath.Dir(manifest),
-			})
-		}
-	}
-
-	return nil
-}
diff --git a/openshift-hack/cmd/k8s-tests/runtest.go b/openshift-hack/cmd/k8s-tests/runtest.go
deleted file mode 100644
index 0abff33438f..00000000000
--- a/openshift-hack/cmd/k8s-tests/runtest.go
+++ /dev/null
@@ -1,143 +0,0 @@
-package main
-
-import (
-	"fmt"
-	"io"
-	"os"
-	"regexp"
-	"strings"
-	"time"
-
-	"github.com/onsi/ginkgo/v2"
-	"github.com/onsi/ginkgo/v2/types"
-
-	"k8s.io/kubernetes/openshift-hack/e2e/annotate/generated"
-
-	// ensure all the ginkgo tests are loaded
-	_ "k8s.io/kubernetes/openshift-hack/e2e"
-)
-
-// TestOptions handles running a single test.
-type TestOptions struct {
-	Out    io.Writer
-	ErrOut io.Writer
-}
-
-var _ ginkgo.GinkgoTestingT = &TestOptions{}
-
-func NewTestOptions(out io.Writer, errOut io.Writer) *TestOptions {
-	return &TestOptions{
-		Out:    out,
-		ErrOut: errOut,
-	}
-}
-
-func (opt *TestOptions) Run(args []string) error {
-	if len(args) != 1 {
-		return fmt.Errorf("only a single test name may be passed")
-	}
-
-	// Ignore the upstream suite behavior within test execution
-	ginkgo.GetSuite().ClearBeforeAndAfterSuiteNodes()
-	tests := testsForSuite()
-	var test *TestCase
-	for _, t := range tests {
-		if t.Name == args[0] {
-			test = t
-			break
-		}
-	}
-	if test == nil {
-		return fmt.Errorf("no test exists with that name: %s", args[0])
-	}
-
-	suiteConfig, reporterConfig := ginkgo.GinkgoConfiguration()
-	suiteConfig.FocusStrings = []string{fmt.Sprintf("^ %s$", regexp.QuoteMeta(test.Name))}
-
-	// These settings are matched to upstream's ginkgo configuration. See:
-	// https://github.com/kubernetes/kubernetes/blob/v1.25.0/test/e2e/framework/test_context.go#L354-L355
-	// Randomize specs as well as suites
-	suiteConfig.RandomizeAllSpecs = true
-	// https://github.com/kubernetes/kubernetes/blob/v1.25.0/hack/ginkgo-e2e.sh#L172-L173
-	suiteConfig.Timeout = 24 * time.Hour
-	reporterConfig.NoColor = true
-	reporterConfig.Verbose = true
-
-	ginkgo.SetReporterConfig(reporterConfig)
-
-	cwd, err := os.Getwd()
-	if err != nil {
-		return err
-	}
-	ginkgo.GetSuite().RunSpec(test.spec, ginkgo.Labels{}, "Kubernetes e2e suite", cwd, ginkgo.GetFailer(), ginkgo.GetWriter(), suiteConfig, reporterConfig)
-
-	var summary types.SpecReport
-	for _, report := range ginkgo.GetSuite().GetReport().SpecReports {
-		if report.NumAttempts > 0 {
-			summary = report
-		}
-	}
-
-	switch {
-	case summary.State == types.SpecStatePassed:
-		// do nothing
-	case summary.State == types.SpecStateSkipped:
-		if len(summary.Failure.Message) > 0 {
-			fmt.Fprintf(opt.ErrOut, "skip [%s:%d]: %s\n", lastFilenameSegment(summary.Failure.Location.FileName), summary.Failure.Location.LineNumber, summary.Failure.Message)
-		}
-		if len(summary.Failure.ForwardedPanic) > 0 {
-			fmt.Fprintf(opt.ErrOut, "skip [%s:%d]: %s\n", lastFilenameSegment(summary.Failure.Location.FileName), summary.Failure.Location.LineNumber, summary.Failure.ForwardedPanic)
-		}
-		return ExitError{Code: 3}
-	case summary.State == types.SpecStateFailed, summary.State == types.SpecStatePanicked, summary.State == types.SpecStateInterrupted:
-		if len(summary.Failure.ForwardedPanic) > 0 {
-			if len(summary.Failure.Location.FullStackTrace) > 0 {
-				fmt.Fprintf(opt.ErrOut, "\n%s\n", summary.Failure.Location.FullStackTrace)
-			}
-			fmt.Fprintf(opt.ErrOut, "fail [%s:%d]: Test Panicked: %s\n", lastFilenameSegment(summary.Failure.Location.FileName), summary.Failure.Location.LineNumber, summary.Failure.ForwardedPanic)
-			return ExitError{Code: 1}
-		}
-		fmt.Fprintf(opt.ErrOut, "fail [%s:%d]: %s\n", lastFilenameSegment(summary.Failure.Location.FileName), summary.Failure.Location.LineNumber, summary.Failure.Message)
-		return ExitError{Code: 1}
-	default:
-		return fmt.Errorf("unrecognized test case outcome: %#v", summary)
-	}
-	return nil
-}
-
-func (opt *TestOptions) Fail() {
-	// this function allows us to pass TestOptions as the first argument,
-	// it's empty becase we have failure check mechanism implemented above.
-}
-
-func lastFilenameSegment(filename string) string {
-	if parts := strings.Split(filename, "/vendor/"); len(parts) > 1 {
-		return parts[len(parts)-1]
-	}
-	if parts := strings.Split(filename, "/src/"); len(parts) > 1 {
-		return parts[len(parts)-1]
-	}
-	return filename
-}
-
-func testsForSuite() []*TestCase {
-	var tests []*TestCase
-
-	// Don't build the tree multiple times, it results in multiple initing of tests
-	if !ginkgo.GetSuite().InPhaseBuildTree() {
-		ginkgo.GetSuite().BuildTree()
-	}
-
-	ginkgo.GetSuite().WalkTests(func(name string, spec types.TestSpec) {
-		testCase := &TestCase{
-			Name:      spec.Text(),
-			locations: spec.CodeLocations(),
-			spec:      spec,
-		}
-		if labels, ok := generated.Annotations[name]; ok {
-			testCase.Labels = labels
-		}
-		tests = append(tests, testCase)
-	})
-	return tests
-}
diff --git a/openshift-hack/cmd/k8s-tests/types.go b/openshift-hack/cmd/k8s-tests/types.go
deleted file mode 100644
index 29a0b5b5efa..00000000000
--- a/openshift-hack/cmd/k8s-tests/types.go
+++ /dev/null
@@ -1,69 +0,0 @@
-package main
-
-import (
-	"fmt"
-
-	"github.com/onsi/ginkgo/v2/types"
-)
-
-// copied directly from github.com/openshift/origin/test/extended/util/cluster/cluster.go
-type ClusterConfiguration struct {
-	ProviderName string `json:"type"`
-
-	// These fields (and the "type" tag for ProviderName) chosen to match
-	// upstream's e2e.CloudConfig.
-	ProjectID   string
-	Region      string
-	Zone        string
-	NumNodes    int
-	MultiMaster bool
-	MultiZone   bool
-	Zones       []string
-	ConfigFile  string
-
-	// Disconnected is set for test jobs without external internet connectivity
-	Disconnected bool
-
-	// SingleReplicaTopology is set for disabling disruptive tests or tests
-	// that require high availability
-	SingleReplicaTopology bool
-
-	// NetworkPlugin is the "official" plugin name
-	NetworkPlugin string
-	// NetworkPluginMode is an optional sub-identifier for the NetworkPlugin.
-	// (Currently it is only used for OpenShiftSDN.)
-	NetworkPluginMode string `json:",omitempty"`
-
-	// HasIPv4 and HasIPv6 determine whether IPv4-specific, IPv6-specific,
-	// and dual-stack-specific tests are run
-	HasIPv4 bool
-	HasIPv6 bool
-
-	// HasSCTP determines whether SCTP connectivity tests can be run in the cluster
-	HasSCTP bool
-
-	// IsProxied determines whether we are accessing the cluster through an HTTP proxy
-	IsProxied bool
-
-	// IsIBMROKS determines whether the cluster is Managed IBM Cloud (ROKS)
-	IsIBMROKS bool
-
-	// IsNoOptionalCapabilities indicates the cluster has no optional capabilities enabled
-	HasNoOptionalCapabilities bool
-}
-
-// copied directly from github.com/openshift/origin/pkg/test/ginkgo/test.go
-type TestCase struct {
-	Name      string
-	Labels    string
-	spec      types.TestSpec
-	locations []types.CodeLocation
-}
-
-type ExitError struct {
-	Code int
-}
-
-func (e ExitError) Error() string {
-	return fmt.Sprintf("exit with code %d", e.Code)
-}
diff --git a/openshift-hack/e2e/annotate/rules.go b/openshift-hack/e2e/annotate/rules.go
index a62f99f1fd9..481e7cc3f8d 100644
--- a/openshift-hack/e2e/annotate/rules.go
+++ b/openshift-hack/e2e/annotate/rules.go
@@ -10,22 +10,19 @@ var (
 		// alpha features that are not gated
 		"[Disabled:Alpha]": {
 			`\[Feature:StorageVersionAPI\]`,
-			`\[Feature:InPlacePodVerticalScaling\]`,
-			`\[Feature:ServiceCIDRs\]`,
 			`\[Feature:ClusterTrustBundle\]`,
 			`\[Feature:SELinuxMount\]`,
 			`\[FeatureGate:SELinuxMount\]`,
 			`\[Feature:UserNamespacesPodSecurityStandards\]`,
-			`\[Feature:UserNamespacesSupport\]`, // disabled Beta
 			`\[Feature:DynamicResourceAllocation\]`,
 			`\[Feature:VolumeAttributesClass\]`, // disabled Beta
 			`\[sig-cli\] Kubectl client Kubectl prune with applyset should apply and prune objects`, // Alpha feature since k8s 1.27
 			// 4.19
 			`\[Feature:PodLevelResources\]`,
-			`\[Feature:SchedulerAsyncPreemption\]`,
-			`\[Feature:RelaxedDNSSearchValidation\]`,
 			`\[Feature:PodLogsQuerySplitStreams\]`,
-			`\[Feature:PodLifecycleSleepActionAllowZero\]`,
+			// 4.20
+			`\[Feature:OffByDefault\]`,
+			`\[Feature:CBOR\]`,
 		},
 		// tests for features that are not implemented in openshift
 		"[Disabled:Unimplemented]": {
@@ -161,7 +158,10 @@ var (
 			`\[sig-node\] \[Feature:PodLifecycleSleepAction\] when create a pod with lifecycle hook using sleep action valid prestop hook using sleep action`,
 
 			// https://issues.redhat.com/browse/OCPBUGS-38839
-			`\[sig-network\] \[Feature:Traffic Distribution\] when Service has trafficDistribution=PreferClose should route traffic to an endpoint that is close to the client`,
+			`\[sig-network\] Traffic Distribution`,
+
+			// https://issues.redhat.com/browse/OCPBUGS-45273
+			`\[sig-network\] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes`,
 		},
 		// tests that need to be temporarily disabled while the rebase is in progress.
 		"[Disabled:RebaseInProgress]": {
@@ -174,25 +174,17 @@ var (
 			// https://issues.redhat.com/browse/OCPBUGS-17194
 			`\[sig-node\] ImageCredentialProvider \[Feature:KubeletCredentialProviders\] should be able to create pod with image credentials fetched from external credential provider`,
 
-			// https://issues.redhat.com/browse/OCPBUGS-45214
-			// Even though this feature is not GA in k/k, it will be GA in OCP 4.19, so we should fix it and unskip this test
-			`\[Feature:volumegroupsnapshot\]`,
+			// Jan will look into this
+			// https://redhat-internal.slack.com/archives/C08KA82J2JF/p1743612984702079
+			`\[Feature:SchedulerAsyncPreemption\]`,
 
-			// https://issues.redhat.com/browse/OCPBUGS-45273
-			`\[sig-network\] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes`,
+			// Requires flipping the gate in o/api after branch cut
+			// https://redhat-internal.slack.com/archives/C08KA82J2JF/p1743447032840259
+			`\[Feature:UserNamespacesSupport\]`,
 
-			// https://issues.redhat.com/browse/OCPBUGS-45273
-			`\[sig-cli\] Kubectl Port forwarding Shutdown client connection while the remote stream is writing data to the port-forward connection port-forward should keep working after detect broken connection`,
-
-			// https://issues.redhat.com/browse/OCPBUGS-45274
-			// https://github.com/kubernetes/kubernetes/issues/129056
-			`\[sig-node\] PodRejectionStatus Kubelet should reject pod when the node didn't have enough resource`,
-
-			// https://issues.redhat.com/browse/OCPBUGS-45359
-			`\[Feature:RecoverVolumeExpansionFailure\]`,
-
-			// https://issues.redhat.com/browse/OCPBUGS-46477
-			`\[sig-storage\] In-tree Volumes \[Driver: azure-file\]`,
+			// Requires flipping the gate in o/api after branch cut
+			// https://redhat-internal.slack.com/archives/C08KA82J2JF/p1744285107158659?thread_ts=1743190159.388209&cid=C08KA82J2JF
+			`\[FeatureGate:SELinuxChangePolicy\]`,
 		},
 		// tests that may work, but we don't support them
 		"[Disabled:Unsupported]": {
@@ -262,6 +254,11 @@ var (
 			`\[sig-network\] LoadBalancers \[Feature:LoadBalancer\] .* UDP`,
 			`\[sig-network\] LoadBalancers \[Feature:LoadBalancer\] .* session affinity`,
 		},
+		"[Skipped:external]": {
+			// LoadBalancer tests in 1.31 require explicit platform-specific skips
+			// https://issues.redhat.com/browse/OCPBUGS-53249
+			`\[sig-network\] LoadBalancers \[Feature:LoadBalancer\] should be able to preserve UDP traffic when server pod cycles for a LoadBalancer service on`,
+		},
 		"[Skipped:azure]": {
 			"Networking should provide Internet connection for containers", // Azure does not allow ICMP traffic to internet.
 			// Azure CSI migration changed how we treat regions without zones.
diff --git a/openshift-hack/e2e/include.go b/openshift-hack/e2e/include.go
index 48efbca4a3e..e0b481a17f0 100644
--- a/openshift-hack/e2e/include.go
+++ b/openshift-hack/e2e/include.go
@@ -10,7 +10,6 @@ package e2e
 import (
 	// define and freeze constants
 	_ "k8s.io/kubernetes/test/e2e/feature"
-	_ "k8s.io/kubernetes/test/e2e/nodefeature"
 
 	// test sources
 	_ "k8s.io/kubernetes/test/e2e/apimachinery"
diff --git a/openshift-hack/e2e/kube_e2e_test.go b/openshift-hack/e2e/kube_e2e_test.go
index 8356774e726..a99ea2ede4d 100644
--- a/openshift-hack/e2e/kube_e2e_test.go
+++ b/openshift-hack/e2e/kube_e2e_test.go
@@ -1,22 +1,22 @@
 package e2e
 
-//go:generate go run -mod vendor ./annotate/cmd -- ./annotate/generated/zz_generated.annotations.go
-
 // This file duplicates most of test/e2e/e2e_test.go but limits the included
 // tests (via include.go) to tests that are relevant to openshift.
 
 import (
 	"context"
+	"encoding/json"
 	"flag"
 	"fmt"
 	"math/rand"
 	"os"
+	"os/exec"
 	"strings"
 	"testing"
 	"time"
 
+	et "github.com/openshift-eng/openshift-tests-extension/pkg/extension/extensiontests"
 	"gopkg.in/yaml.v2"
-
 	// Never, ever remove the line with "/ginkgo". Without it,
 	// the ginkgo test runner will not detect that this
 	// directory contains a Ginkgo test suite.
@@ -35,9 +35,6 @@ import (
 	e2etestingmanifests "k8s.io/kubernetes/test/e2e/testing-manifests"
 	testfixtures "k8s.io/kubernetes/test/fixtures"
 	"k8s.io/kubernetes/test/utils/image"
-
-	// Ensure test annotation
-	"k8s.io/kubernetes/openshift-hack/e2e/annotate/generated"
 )
 
 func TestMain(m *testing.M) {
@@ -109,17 +106,43 @@ func TestMain(m *testing.M) {
 }
 
 func TestE2E(t *testing.T) {
-	// TODO(soltysh): this is raw copy from end of openshift-hack/e2e/annotate/generated/zz_generated.annotations.go
-	// https://issues.redhat.com/browse/OCPBUGS-25641
+	// In order to properly skip tests, we must add the labels that the OTE external binary supplies to the test name
+	// This will then be used by Ginkgo to skip specific tests
+	oteCmd := exec.Command("k8s-tests-ext", "list", "tests")
+	// We can't have OTE also add annotations to the spec names to map to labels, or they won't match the actual spec names
+	//TODO(sgoeddel): once annotation logic is removed, this can be as well
+	oteCmd.Env = append(oteCmd.Env, "OMIT_ANNOTATIONS=true")
+	oteCmd.Stderr = os.Stderr
+	output, err := oteCmd.Output()
+	if err != nil {
+		t.Fatalf("Error running ote list tests command: %v", err)
+	}
+	var specs et.ExtensionTestSpecs
+	if err = json.Unmarshal(output, &specs); err != nil {
+		t.Fatalf("Error parsing ote list tests output: %v", err)
+	}
+
+	nameToLabels := make(map[string][]string, len(specs))
+	for _, spec := range specs {
+		nameToLabels[spec.Name] = spec.Labels.UnsortedList()
+	}
+
 	ginkgo.GetSuite().SetAnnotateFn(func(name string, node types.TestSpec) {
-		if newLabels, ok := generated.Annotations[name]; ok {
-			node.AppendText(newLabels)
+		if newLabels, ok := nameToLabels[name]; ok {
+			for _, label := range newLabels {
+				// Only add the label to the name if it isn't already present to avoid test names that are too long
+				if !strings.Contains(name, label) {
+					node.AppendText(fmt.Sprintf(" %s", label))
+				}
+			}
 		} else {
-			panic(fmt.Sprintf("unable to find test %s", name))
+			// If the name isn't found in the mapping, it is because the test has been disabled via OTE
+			node.AppendText(" [Disabled:missing]")
 		}
 		if strings.Contains(name, "Kubectl client Kubectl prune with applyset should apply and prune objects") {
 			fmt.Printf("Trying to annotate %q\n", name)
 		}
+
 	})
 
 	e2e.RunE2ETests(t)
diff --git a/openshift-hack/images/hyperkube/Dockerfile.rhel b/openshift-hack/images/hyperkube/Dockerfile.rhel
index fabdce0b9c0..22c75dcaacb 100644
--- a/openshift-hack/images/hyperkube/Dockerfile.rhel
+++ b/openshift-hack/images/hyperkube/Dockerfile.rhel
@@ -1,10 +1,10 @@
-FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.23-openshift-4.19 AS builder
+FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.24-nofips-openshift-4.19 AS builder
 WORKDIR /go/src/k8s.io/kubernetes
 COPY . .
-RUN make WHAT='cmd/kube-apiserver cmd/kube-controller-manager cmd/kube-scheduler cmd/kubelet cmd/watch-termination openshift-hack/cmd/k8s-tests openshift-hack/cmd/k8s-tests-ext' && \
+RUN make WHAT='cmd/kube-apiserver cmd/kube-controller-manager cmd/kube-scheduler cmd/kubelet cmd/watch-termination openshift-hack/cmd/k8s-tests-ext' && \
     mkdir -p /tmp/build && \
     cp openshift-hack/images/hyperkube/hyperkube openshift-hack/images/hyperkube/kubensenter /tmp/build && \
-    cp /go/src/k8s.io/kubernetes/_output/local/bin/linux/$(go env GOARCH)/{kube-apiserver,kube-controller-manager,kube-scheduler,kubelet,watch-termination,k8s-tests,k8s-tests-ext} \
+    cp /go/src/k8s.io/kubernetes/_output/local/bin/linux/$(go env GOARCH)/{kube-apiserver,kube-controller-manager,kube-scheduler,kubelet,watch-termination,k8s-tests-ext} \
     /tmp/build && \
     gzip /tmp/build/k8s-tests-ext
 
@@ -14,4 +14,4 @@ COPY --from=builder /tmp/build/* /usr/bin/
 LABEL io.k8s.display-name="OpenShift Kubernetes Server Commands" \
       io.k8s.description="OpenShift is a platform for developing, building, and deploying containerized applications." \
       io.openshift.tags="openshift,hyperkube" \
-      io.openshift.build.versions="kubernetes=1.32.1"
\ No newline at end of file
+      io.openshift.build.versions="kubernetes=1.33.0"
\ No newline at end of file
diff --git a/openshift-hack/images/installer-kube-apiserver-artifacts/Dockerfile.rhel b/openshift-hack/images/installer-kube-apiserver-artifacts/Dockerfile.rhel
index fb57a6042fe..ecf3d1828a9 100644
--- a/openshift-hack/images/installer-kube-apiserver-artifacts/Dockerfile.rhel
+++ b/openshift-hack/images/installer-kube-apiserver-artifacts/Dockerfile.rhel
@@ -2,7 +2,7 @@
 # the kube-apiserver layered on top of the cluster-native Linux installer image.
 # The resulting image is used to build the openshift-install binary.
 
-FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.23-openshift-4.19 AS macbuilder
+FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.24-nofips-openshift-4.19 AS macbuilder
 ARG TAGS=""
 WORKDIR /go/src/k8s.io/kubernetes
 COPY . .
@@ -10,7 +10,7 @@ ENV KUBE_BUILD_PLATFORMS=darwin/amd64
 ENV KUBE_STATIC_OVERRIDES=kube-apiserver
 RUN make WHAT='cmd/kube-apiserver'
 
-FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.23-openshift-4.19 AS macarmbuilder
+FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.24-nofips-openshift-4.19 AS macarmbuilder
 ARG TAGS=""
 WORKDIR /go/src/k8s.io/kubernetes
 COPY . .
@@ -18,7 +18,7 @@ ENV KUBE_BUILD_PLATFORMS=darwin/arm64
 ENV KUBE_STATIC_OVERRIDES=kube-apiserver
 RUN make WHAT='cmd/kube-apiserver'
 
-FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.23-openshift-4.19 AS linuxbuilder
+FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.24-nofips-openshift-4.19 AS linuxbuilder
 ARG TAGS=""
 WORKDIR /go/src/k8s.io/kubernetes
 COPY . .
@@ -27,7 +27,7 @@ ENV KUBE_BUILD_PLATFORMS=linux/amd64
 ENV KUBE_STATIC_OVERRIDES=kube-apiserver
 RUN make WHAT='cmd/kube-apiserver'
 
-FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.23-openshift-4.19 AS linuxarmbuilder
+FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.24-nofips-openshift-4.19 AS linuxarmbuilder
 ARG TAGS=""
 WORKDIR /go/src/k8s.io/kubernetes
 COPY . .
@@ -36,7 +36,7 @@ ENV KUBE_BUILD_PLATFORMS=linux/arm64
 ENV KUBE_STATIC_OVERRIDES=kube-apiserver
 RUN make WHAT='cmd/kube-apiserver'
 
-FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.23-openshift-4.19 AS builder
+FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.24-nofips-openshift-4.19 AS builder
 ARG TAGS=""
 WORKDIR /go/src/k8s.io/kubernetes
 COPY . .
diff --git a/openshift-hack/images/kube-proxy/Dockerfile.rhel b/openshift-hack/images/kube-proxy/Dockerfile.rhel
index 619ce5942b8..088acdb04bd 100644
--- a/openshift-hack/images/kube-proxy/Dockerfile.rhel
+++ b/openshift-hack/images/kube-proxy/Dockerfile.rhel
@@ -1,4 +1,4 @@
-FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.23-openshift-4.19 AS builder
+FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.24-nofips-openshift-4.19 AS builder
 WORKDIR /go/src/k8s.io/kubernetes
 COPY . .
 RUN make WHAT='cmd/kube-proxy' && \
diff --git a/openshift-hack/images/kube-proxy/test-kube-proxy.sh b/openshift-hack/images/kube-proxy/test-kube-proxy.sh
index 514b52eff28..b012db5a4d1 100755
--- a/openshift-hack/images/kube-proxy/test-kube-proxy.sh
+++ b/openshift-hack/images/kube-proxy/test-kube-proxy.sh
@@ -87,6 +87,13 @@ rules:
   - get
   - list
   - watch
+- apiGroups: ["networking.k8s.io"]
+  resources:
+  - servicecidrs
+  verbs:
+  - get
+  - list
+  - watch
 ---
 apiVersion: v1
 kind: ServiceAccount
@@ -185,7 +192,12 @@ oc wait --for=condition=Ready -n kube-proxy-test pod/kube-proxy
 echo "Waiting for kube-proxy to program initial ${PROXY_MODE} rules..."
 function kube_proxy_synced() {
     oc exec -n kube-proxy-test kube-proxy -- curl -s http://127.0.0.1:10249/metrics > "${TMPDIR}/metrics.txt"
-    grep -q '^kubeproxy_sync_proxy_rules_duration_seconds_count [^0]' "${TMPDIR}/metrics.txt"
+    # kube-proxy < 1.33 has a single sync_proxy_rules_duration_seconds_count metric.
+    # kube-proxy >= 1.33 has the metric labeled by IP family, so we wait until both
+    # the IPv4 and IPv6 syncs have happened.
+    sync_metrics="$(grep -c '^kubeproxy_sync_proxy_rules_duration_seconds_count' "${TMPDIR}/metrics.txt")" || return 1
+    nonzero_sync_metrics="$(grep -c '^kubeproxy_sync_proxy_rules_duration_seconds_count[^ ]* [^0]' "${TMPDIR}/metrics.txt")" || return 1
+    [[ "${sync_metrics}" -eq "${nonzero_sync_metrics}" ]]
 }
 synced=false
 for count in $(seq 1 10); do
diff --git a/openshift-hack/images/tests/Dockerfile.rhel b/openshift-hack/images/tests/Dockerfile.rhel
index ff0b2fa6e1d..3cd421bc12e 100644
--- a/openshift-hack/images/tests/Dockerfile.rhel
+++ b/openshift-hack/images/tests/Dockerfile.rhel
@@ -1,17 +1,20 @@
-FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.23-openshift-4.19 AS builder
+FROM registry.ci.openshift.org/ocp/builder:rhel-9-golang-1.24-nofips-openshift-4.19 AS builder
 WORKDIR /go/src/k8s.io/kubernetes
 COPY . .
 RUN make WHAT=openshift-hack/e2e/k8s-e2e.test; \
     make WHAT=vendor/github.com/onsi/ginkgo/v2/ginkgo; \
+    make WHAT=openshift-hack/cmd/k8s-tests-ext; \
     mkdir -p /tmp/build; \
     cp /go/src/k8s.io/kubernetes/_output/local/bin/linux/$(go env GOARCH)/k8s-e2e.test /tmp/build/; \
     cp /go/src/k8s.io/kubernetes/_output/local/bin/linux/$(go env GOARCH)/ginkgo /tmp/build/; \
+    cp /go/src/k8s.io/kubernetes/_output/local/bin/linux/$(go env GOARCH)/k8s-tests-ext /tmp/build/; \
     cp /go/src/k8s.io/kubernetes/openshift-hack/test-kubernetes-e2e.sh /tmp/build/; \
     cp /go/src/k8s.io/kubernetes/openshift-hack/images/kube-proxy/test-kube-proxy.sh /tmp/build/
 
 FROM registry.ci.openshift.org/ocp/4.19:tools
 COPY --from=builder /tmp/build/k8s-e2e.test /usr/bin/
 COPY --from=builder /tmp/build/ginkgo /usr/bin/
+COPY --from=builder /tmp/build/k8s-tests-ext /usr/bin/
 COPY --from=builder /tmp/build/test-kubernetes-e2e.sh /usr/bin/
 COPY --from=builder /tmp/build/test-kube-proxy.sh /usr/bin/
 RUN yum install --setopt=tsflags=nodocs -y git gzip util-linux && yum clean all && rm -rf /var/cache/yum/* && \
diff --git a/openshift-hack/test-kubernetes-e2e.sh b/openshift-hack/test-kubernetes-e2e.sh
index efa25590ee0..b74bd86c12d 100755
--- a/openshift-hack/test-kubernetes-e2e.sh
+++ b/openshift-hack/test-kubernetes-e2e.sh
@@ -54,12 +54,13 @@ esac
 # -skip and -focus.
 KUBE_E2E_TEST_ARGS="${KUBE_E2E_TEST_ARGS:-${DEFAULT_TEST_ARGS}}"
 
-# k8s-e2e.test and ginkgo are expected to be in the path in
+# k8s-e2e.test, ginkgo, and k8s-tests-ext are expected to be in the path in
 # CI. Outside of CI, ensure k8s-e2e.test and ginkgo are built and
 # available in PATH.
 if ! which k8s-e2e.test &> /dev/null; then
   make WHAT=vendor/github.com/onsi/ginkgo/v2/ginkgo
   make WHAT=openshift-hack/e2e/k8s-e2e.test
+  make WHAT=openshift-hack/cmd/k8s-tests-ext
   ROOT_PATH="$(cd "$(dirname "${BASH_SOURCE[0]}")/.."; pwd -P)"
   PATH="${ROOT_PATH}/_output/local/bin/$(go env GOHOSTOS)/$(go env GOARCH):${PATH}"
   export PATH
@@ -85,6 +86,7 @@ ginkgo \
   --output-interceptor-mode=none \
   -nodes "${NODES}" -no-color ${KUBE_E2E_TEST_ARGS} \
   "$( which k8s-e2e.test )" -- \
+  -node-os-distro "custom" \
   -report-dir "${test_report_dir}" \
   -host "${SERVER}" \
   -allowed-not-ready-nodes ${unschedulable} \
-- 
2.49.0


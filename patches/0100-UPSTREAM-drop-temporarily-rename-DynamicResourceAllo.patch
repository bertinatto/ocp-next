From 131c708cb64f839b10bac85dae45edc1ffe71f22 Mon Sep 17 00:00:00 2001
From: Fabio Bertinatto <fbertina@redhat.com>
Date: Mon, 7 Aug 2023 14:26:59 -0300
Subject: [PATCH] UPSTREAM: <drop>: temporarily rename
 DynamicResourceAllocation feature to make it impossible to enabled it

---
 openshift-hack/e2e/annotate/rules.go          |  3 +
 pkg/features/kube_features.go                 |  2 +-
 .../config/performance-config.yaml            | 64 -------------------
 3 files changed, 4 insertions(+), 65 deletions(-)

diff --git a/openshift-hack/e2e/annotate/rules.go b/openshift-hack/e2e/annotate/rules.go
index 3d8c6af1a31..50a58140d7d 100644
--- a/openshift-hack/e2e/annotate/rules.go
+++ b/openshift-hack/e2e/annotate/rules.go
@@ -163,6 +163,9 @@ var (
 
 			// https://issues.redhat.com/browse/OCPBUGS-17202
 			`\[sig-apps\] StatefulSet Scaling StatefulSetStartOrdinal \[Feature:StatefulSetStartOrdinal\] Removing \.start\.ordinal`,
+
+			// https://issues.redhat.com/browse/OCPBUGS-17436
+			`\[Feature:DynamicResourceAllocation\]`,
 		},
 		// tests that may work, but we don't support them
 		"[Disabled:Unsupported]": {
diff --git a/pkg/features/kube_features.go b/pkg/features/kube_features.go
index ead01767b0b..dd6391e898c 100644
--- a/pkg/features/kube_features.go
+++ b/pkg/features/kube_features.go
@@ -245,7 +245,7 @@ const (
 	//
 	// Enables support for resources with custom parameters and a lifecycle
 	// that is independent of a Pod.
-	DynamicResourceAllocation featuregate.Feature = "DynamicResourceAllocation"
+	DynamicResourceAllocation featuregate.Feature = "DynamicResourceAllocation_xxx"
 
 	// owner: @harche
 	// kep: http://kep.k8s.io/3386
diff --git a/test/integration/scheduler_perf/config/performance-config.yaml b/test/integration/scheduler_perf/config/performance-config.yaml
index 6d2d0e4ac2e..9638e2e3166 100644
--- a/test/integration/scheduler_perf/config/performance-config.yaml
+++ b/test/integration/scheduler_perf/config/performance-config.yaml
@@ -713,67 +713,3 @@
       taintNodes: 1000
       normalNodes: 4000
       measurePods: 4000
-
-# SchedulingWithResourceClaimTemplate uses a ResourceClaimTemplate
-# and dynamically created ResourceClaim instances for each pod.
-- name: SchedulingWithResourceClaimTemplate
-  featureGates:
-    DynamicResourceAllocation: true
-  workloadTemplate:
-  - opcode: createNodes
-    countParam: $nodesWithoutDRA
-  - opcode: createNodes
-    nodeTemplatePath: config/dra/node-with-dra-test-driver.yaml
-    countParam: $nodesWithDRA
-  - opcode: createResourceDriver
-    driverName: test-driver.cdi.k8s.io
-    nodes: scheduler-perf-dra-*
-    maxClaimsPerNodeParam: $maxClaimsPerNode
-  - opcode: createResourceClass
-    templatePath: config/dra/resourceclass.yaml
-  - opcode: createResourceClaimTemplate
-    templatePath: config/dra/resourceclaimtemplate.yaml
-    namespace: init
-  - opcode: createPods
-    namespace: init
-    countParam: $initPods
-    podTemplatePath: config/dra/pod-with-claim-template.yaml
-  - opcode: createResourceClaimTemplate
-    templatePath: config/dra/resourceclaimtemplate.yaml
-    namespace: test
-  - opcode: createPods
-    namespace: test
-    countParam: $measurePods
-    podTemplatePath: config/dra/pod-with-claim-template.yaml
-    collectMetrics: true
-  workloads:
-  - name: fast
-    labels: [integration-test, fast]
-    params:
-      # This testcase runs through all code paths without
-      # taking too long overall.
-      nodesWithDRA: 1
-      nodesWithoutDRA: 1
-      initPods: 0
-      measurePods: 10
-      maxClaimsPerNode: 10
-  - name: 2000pods_100nodes
-    labels: [performance, fast]
-    params:
-      # In this testcase, the number of nodes is smaller
-      # than the limit for the PodScheduling slices.
-      nodesWithDRA: 100
-      nodesWithoutDRA: 0
-      initPods: 1000
-      measurePods: 1000
-      maxClaimsPerNode: 20
-  - name: 2000pods_200nodes
-    params:
-      # In this testcase, the driver and scheduler must
-      # truncate the PotentialNodes and UnsuitableNodes
-      # slices.
-      nodesWithDRA: 200
-      nodesWithoutDRA: 0
-      initPods: 1000
-      measurePods: 1000
-      maxClaimsPerNode: 10
-- 
2.41.0


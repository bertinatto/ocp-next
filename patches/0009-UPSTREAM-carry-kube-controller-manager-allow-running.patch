From 38e55a3bd534864fe9ca73ca800f17c2f986dd59 Mon Sep 17 00:00:00 2001
From: David Eads <deads@redhat.com>
Date: Thu, 29 Oct 2020 13:55:56 +0100
Subject: [PATCH] UPSTREAM: <carry>: kube-controller-manager: allow running
 bare kube-controller-manager

UPSTREAM: <carry>: (squash) kube-controller-manager: allow running bare kube-controller-manager

UPSTREAM: <carry>: kube-controller-manager: allow running bare kube-controller-manager

UPSTREAM: <carry>: (squash) remove egressnetworkpolicies from gc ignored resources

egressnetworkpolicies should not be in garbage collector ignored
resources, so users can delete them using "--cascade=foreground" flag.

Signed-off-by: Flavio Fernandes <flaviof@redhat.com>

OpenShift-Rebase-Source: 6c1dee4c18f

UPSTREAM: <carry>: (squash) kube-controller-manager: allow running bare kube-controller-manager

UPSTREAM: <carry>: kube-controller-manager: allow running bare kube-controller-manager

UPSTREAM: <carry>: kube-controller-manager: allow running bare kube-controller-manager

Fix garbage-collection for CRDs.

These types are backed by a CRD and not by openshift-apiserver anymore.

DefaultGarbageCollectionPolicy (Unsupported) does not work with CRDs.
The `foregroundDeletion` finalizer was set on these CRD objects which
blocks deletion indifinetelly as GC will ignore these resources.
---
 cmd/kube-controller-manager/app/apps.go       |   5 +-
 .../app/config/config.go                      |   2 +
 .../app/config/patch.go                       |   9 +
 .../app/controllermanager.go                  |  19 +-
 .../app/options/options.go                    |   6 +
 cmd/kube-controller-manager/app/patch.go      |  84 +++++
 cmd/kube-controller-manager/app/patch_gc.go   |  37 +++
 .../app/patch_informers_openshift.go          | 293 ++++++++++++++++++
 .../app/patch_satoken.go                      |  87 ++++++
 pkg/controller/daemon/daemon_controller.go    |  24 +-
 pkg/controller/daemon/patch_nodeselector.go   | 109 +++++++
 .../daemon/patch_nodeselector_test.go         | 186 +++++++++++
 12 files changed, 850 insertions(+), 11 deletions(-)
 create mode 100644 cmd/kube-controller-manager/app/config/patch.go
 create mode 100644 cmd/kube-controller-manager/app/patch.go
 create mode 100644 cmd/kube-controller-manager/app/patch_gc.go
 create mode 100644 cmd/kube-controller-manager/app/patch_informers_openshift.go
 create mode 100644 cmd/kube-controller-manager/app/patch_satoken.go
 create mode 100644 pkg/controller/daemon/patch_nodeselector.go
 create mode 100644 pkg/controller/daemon/patch_nodeselector_test.go

diff --git a/cmd/kube-controller-manager/app/apps.go b/cmd/kube-controller-manager/app/apps.go
index 20f9523d050..b1f84a480de 100644
--- a/cmd/kube-controller-manager/app/apps.go
+++ b/cmd/kube-controller-manager/app/apps.go
@@ -41,8 +41,11 @@ func newDaemonSetControllerDescriptor() *ControllerDescriptor {
 	}
 }
 func startDaemonSetController(ctx context.Context, controllerContext ControllerContext, controllerName string) (controller.Interface, bool, error) {
-	dsc, err := daemon.NewDaemonSetsController(
+	dsc, err := daemon.NewNodeSelectorAwareDaemonSetsController(
 		ctx,
+		controllerContext.OpenShiftContext.OpenShiftDefaultProjectNodeSelector,
+		controllerContext.OpenShiftContext.KubeDefaultProjectNodeSelector,
+		controllerContext.InformerFactory.Core().V1().Namespaces(),
 		controllerContext.InformerFactory.Apps().V1().DaemonSets(),
 		controllerContext.InformerFactory.Apps().V1().ControllerRevisions(),
 		controllerContext.InformerFactory.Core().V1().Pods(),
diff --git a/cmd/kube-controller-manager/app/config/config.go b/cmd/kube-controller-manager/app/config/config.go
index 3034f288d91..efadc56383b 100644
--- a/cmd/kube-controller-manager/app/config/config.go
+++ b/cmd/kube-controller-manager/app/config/config.go
@@ -26,6 +26,8 @@ import (
 
 // Config is the main context object for the controller manager.
 type Config struct {
+	OpenShiftContext OpenShiftContext
+
 	ComponentConfig kubectrlmgrconfig.KubeControllerManagerConfiguration
 
 	SecureServing *apiserver.SecureServingInfo
diff --git a/cmd/kube-controller-manager/app/config/patch.go b/cmd/kube-controller-manager/app/config/patch.go
new file mode 100644
index 00000000000..a7112d003d4
--- /dev/null
+++ b/cmd/kube-controller-manager/app/config/patch.go
@@ -0,0 +1,9 @@
+package config
+
+// OpenShiftContext is additional context that we need to launch the kube-controller-manager for openshift.
+// Basically, this holds our additional config information.
+type OpenShiftContext struct {
+	OpenShiftConfig                     string
+	OpenShiftDefaultProjectNodeSelector string
+	KubeDefaultProjectNodeSelector      string
+}
diff --git a/cmd/kube-controller-manager/app/controllermanager.go b/cmd/kube-controller-manager/app/controllermanager.go
index 2c4782a18ba..4174f962da9 100644
--- a/cmd/kube-controller-manager/app/controllermanager.go
+++ b/cmd/kube-controller-manager/app/controllermanager.go
@@ -137,6 +137,11 @@ controller, and serviceaccounts controller.`,
 				return err
 			}
 
+			if err := ShimForOpenShift(s, c); err != nil {
+				fmt.Fprintf(os.Stderr, "%v\n", err)
+				return err
+			}
+
 			// add feature enablement metrics
 			fg := s.ComponentGlobalsRegistry.FeatureGateFor(featuregate.DefaultKubeComponent)
 			fg.(featuregate.MutableFeatureGate).AddMetrics()
@@ -364,6 +369,8 @@ func Run(ctx context.Context, c *config.CompletedConfig) error {
 
 // ControllerContext defines the context object for controller
 type ControllerContext struct {
+	OpenShiftContext config.OpenShiftContext
+
 	// ClientBuilder will provide a client for this controller to use
 	ClientBuilder clientbuilder.ControllerClientBuilder
 
@@ -604,7 +611,12 @@ func CreateControllerContext(ctx context.Context, s *config.CompletedConfig, roo
 	}
 
 	versionedClient := rootClientBuilder.ClientOrDie("shared-informers")
-	sharedInformers := informers.NewSharedInformerFactoryWithOptions(versionedClient, ResyncPeriod(s)(), informers.WithTransform(trim))
+	var sharedInformers informers.SharedInformerFactory
+	if InformerFactoryOverride == nil {
+		sharedInformers = informers.NewSharedInformerFactoryWithOptions(versionedClient, ResyncPeriod(s)(), informers.WithTransform(trim))
+	} else {
+		sharedInformers = InformerFactoryOverride
+	}
 
 	metadataClient := metadata.NewForConfigOrDie(rootClientBuilder.ConfigOrDie("metadata-informers"))
 	metadataInformers := metadatainformer.NewSharedInformerFactoryWithOptions(metadataClient, ResyncPeriod(s)(), metadatainformer.WithTransform(trim))
@@ -624,6 +636,7 @@ func CreateControllerContext(ctx context.Context, s *config.CompletedConfig, roo
 	}, 30*time.Second, ctx.Done())
 
 	controllerContext := ControllerContext{
+		OpenShiftContext:                s.OpenShiftContext,
 		ClientBuilder:                   clientBuilder,
 		InformerFactory:                 sharedInformers,
 		ObjectOrMetadataInformerFactory: informerfactory.NewInformerFactory(sharedInformers, metadataInformers),
@@ -805,10 +818,10 @@ func startServiceAccountTokenController(ctx context.Context, controllerContext C
 		controllerContext.InformerFactory.Core().V1().ServiceAccounts(),
 		controllerContext.InformerFactory.Core().V1().Secrets(),
 		rootClientBuilder.ClientOrDie("tokens-controller"),
-		serviceaccountcontroller.TokensControllerOptions{
+		applyOpenShiftServiceServingCertCA(serviceaccountcontroller.TokensControllerOptions{
 			TokenGenerator: tokenGenerator,
 			RootCA:         rootCA,
-		},
+		}),
 	)
 	if err != nil {
 		return nil, true, fmt.Errorf("error creating Tokens controller: %v", err)
diff --git a/cmd/kube-controller-manager/app/options/options.go b/cmd/kube-controller-manager/app/options/options.go
index 7556d946922..3b87a366ff6 100644
--- a/cmd/kube-controller-manager/app/options/options.go
+++ b/cmd/kube-controller-manager/app/options/options.go
@@ -107,6 +107,7 @@ type KubeControllerManagerOptions struct {
 
 	// ComponentGlobalsRegistry is the registry where the effective versions and feature gates for all components are stored.
 	ComponentGlobalsRegistry featuregate.ComponentGlobalsRegistry
+	OpenShiftContext         kubecontrollerconfig.OpenShiftContext
 }
 
 // NewKubeControllerManagerOptions creates a new KubeControllerManagerOptions with a default config.
@@ -301,6 +302,8 @@ func (s *KubeControllerManagerOptions) Flags(allControllers []string, disabledBy
 	}
 
 	s.ComponentGlobalsRegistry.AddFlags(fss.FlagSet("generic"))
+	fs.StringVar(&s.OpenShiftContext.OpenShiftConfig, "openshift-config", s.OpenShiftContext.OpenShiftConfig, "indicates that this process should be compatible with openshift start master")
+	fs.MarkHidden("openshift-config")
 
 	return fss
 }
@@ -408,6 +411,9 @@ func (s *KubeControllerManagerOptions) ApplyTo(c *kubecontrollerconfig.Config, a
 			return err
 		}
 	}
+
+	c.OpenShiftContext = s.OpenShiftContext
+
 	return nil
 }
 
diff --git a/cmd/kube-controller-manager/app/patch.go b/cmd/kube-controller-manager/app/patch.go
new file mode 100644
index 00000000000..5d85c022993
--- /dev/null
+++ b/cmd/kube-controller-manager/app/patch.go
@@ -0,0 +1,84 @@
+package app
+
+import (
+	"io/ioutil"
+	"path"
+
+	"k8s.io/apimachinery/pkg/util/json"
+	kyaml "k8s.io/apimachinery/pkg/util/yaml"
+	"k8s.io/client-go/informers"
+	"k8s.io/kubernetes/cmd/kube-controller-manager/app/config"
+	"k8s.io/kubernetes/cmd/kube-controller-manager/app/options"
+)
+
+var InformerFactoryOverride informers.SharedInformerFactory
+
+func ShimForOpenShift(controllerManagerOptions *options.KubeControllerManagerOptions, controllerManager *config.Config) error {
+	if len(controllerManager.OpenShiftContext.OpenShiftConfig) == 0 {
+		return nil
+	}
+
+	// TODO this gets removed when no longer take flags and no longer build a recycler template
+	openshiftConfig, err := getOpenShiftConfig(controllerManager.OpenShiftContext.OpenShiftConfig)
+	if err != nil {
+		return err
+	}
+
+	// TODO this should be replaced by using a flex volume to inject service serving cert CAs into pods instead of adding it to the sa token
+	if err := applyOpenShiftServiceServingCertCAFunc(path.Dir(controllerManager.OpenShiftContext.OpenShiftConfig), openshiftConfig); err != nil {
+		return err
+	}
+
+	// skip GC on some openshift resources
+	// TODO this should be replaced by discovery information in some way
+	if err := applyOpenShiftGCConfig(controllerManager); err != nil {
+		return err
+	}
+
+	if err := applyOpenShiftConfigDefaultProjectSelector(controllerManagerOptions, openshiftConfig); err != nil {
+		return err
+	}
+
+	// Overwrite the informers, because we have our custom generic informers for quota.
+	// TODO update quota to create its own informer like garbage collection
+	if informers, err := newInformerFactory(controllerManager.Kubeconfig); err != nil {
+		return err
+	} else {
+		InformerFactoryOverride = informers
+	}
+
+	return nil
+}
+
+func getOpenShiftConfig(configFile string) (map[string]interface{}, error) {
+	configBytes, err := ioutil.ReadFile(configFile)
+	if err != nil {
+		return nil, err
+	}
+	jsonBytes, err := kyaml.ToJSON(configBytes)
+	if err != nil {
+		return nil, err
+	}
+	config := map[string]interface{}{}
+	if err := json.Unmarshal(jsonBytes, &config); err != nil {
+		return nil, err
+	}
+
+	return config, nil
+}
+
+func applyOpenShiftConfigDefaultProjectSelector(controllerManagerOptions *options.KubeControllerManagerOptions, openshiftConfig map[string]interface{}) error {
+	projectConfig, ok := openshiftConfig["projectConfig"]
+	if !ok {
+		return nil
+	}
+
+	castProjectConfig := projectConfig.(map[string]interface{})
+	defaultNodeSelector, ok := castProjectConfig["defaultNodeSelector"]
+	if !ok {
+		return nil
+	}
+	controllerManagerOptions.OpenShiftContext.OpenShiftDefaultProjectNodeSelector = defaultNodeSelector.(string)
+
+	return nil
+}
diff --git a/cmd/kube-controller-manager/app/patch_gc.go b/cmd/kube-controller-manager/app/patch_gc.go
new file mode 100644
index 00000000000..53285c96f86
--- /dev/null
+++ b/cmd/kube-controller-manager/app/patch_gc.go
@@ -0,0 +1,37 @@
+package app
+
+import (
+	gcconfig "k8s.io/kubernetes/pkg/controller/garbagecollector/config"
+
+	"k8s.io/kubernetes/cmd/kube-controller-manager/app/config"
+)
+
+func applyOpenShiftGCConfig(controllerManager *config.Config) error {
+	// TODO make this configurable or discoverable.  This is going to prevent us from running the stock GC controller
+	// IF YOU ADD ANYTHING TO THIS LIST, MAKE SURE THAT YOU UPDATE THEIR STRATEGIES TO PREVENT GC FINALIZERS
+	//
+	// DO NOT PUT CRDs into the list. apiexstension-apiserver does not implement GarbageCollectionPolicy
+	// so the deletion of these will be blocked because of foregroundDeletion finalizer when foreground deletion strategy is specified.
+	controllerManager.ComponentConfig.GarbageCollectorController.GCIgnoredResources = append(controllerManager.ComponentConfig.GarbageCollectorController.GCIgnoredResources,
+		// explicitly disabled from GC for now - not enough value to track them
+		gcconfig.GroupResource{Group: "oauth.openshift.io", Resource: "oauthclientauthorizations"},
+		gcconfig.GroupResource{Group: "oauth.openshift.io", Resource: "oauthclients"},
+		gcconfig.GroupResource{Group: "user.openshift.io", Resource: "groups"},
+		gcconfig.GroupResource{Group: "user.openshift.io", Resource: "identities"},
+		gcconfig.GroupResource{Group: "user.openshift.io", Resource: "users"},
+		gcconfig.GroupResource{Group: "image.openshift.io", Resource: "images"},
+
+		// virtual resource
+		gcconfig.GroupResource{Group: "project.openshift.io", Resource: "projects"},
+		// virtual and unwatchable resource, surfaced via rbac.authorization.k8s.io objects
+		gcconfig.GroupResource{Group: "authorization.openshift.io", Resource: "clusterroles"},
+		gcconfig.GroupResource{Group: "authorization.openshift.io", Resource: "clusterrolebindings"},
+		gcconfig.GroupResource{Group: "authorization.openshift.io", Resource: "roles"},
+		gcconfig.GroupResource{Group: "authorization.openshift.io", Resource: "rolebindings"},
+		// these resources contain security information in their names, and we don't need to track them
+		gcconfig.GroupResource{Group: "oauth.openshift.io", Resource: "oauthaccesstokens"},
+		gcconfig.GroupResource{Group: "oauth.openshift.io", Resource: "oauthauthorizetokens"},
+	)
+
+	return nil
+}
diff --git a/cmd/kube-controller-manager/app/patch_informers_openshift.go b/cmd/kube-controller-manager/app/patch_informers_openshift.go
new file mode 100644
index 00000000000..0c032dec304
--- /dev/null
+++ b/cmd/kube-controller-manager/app/patch_informers_openshift.go
@@ -0,0 +1,293 @@
+package app
+
+import (
+	"time"
+
+	"k8s.io/klog/v2"
+
+	"k8s.io/apimachinery/pkg/api/meta"
+	"k8s.io/apimachinery/pkg/runtime/schema"
+	"k8s.io/client-go/informers"
+	"k8s.io/client-go/kubernetes"
+	"k8s.io/client-go/rest"
+
+	appclient "github.com/openshift/client-go/apps/clientset/versioned"
+	appinformer "github.com/openshift/client-go/apps/informers/externalversions"
+	authorizationclient "github.com/openshift/client-go/authorization/clientset/versioned"
+	authorizationinformer "github.com/openshift/client-go/authorization/informers/externalversions"
+	buildclient "github.com/openshift/client-go/build/clientset/versioned"
+	buildinformer "github.com/openshift/client-go/build/informers/externalversions"
+	imageclient "github.com/openshift/client-go/image/clientset/versioned"
+	imageinformer "github.com/openshift/client-go/image/informers/externalversions"
+	networkclient "github.com/openshift/client-go/network/clientset/versioned"
+	networkinformer "github.com/openshift/client-go/network/informers/externalversions"
+	oauthclient "github.com/openshift/client-go/oauth/clientset/versioned"
+	oauthinformer "github.com/openshift/client-go/oauth/informers/externalversions"
+	quotaclient "github.com/openshift/client-go/quota/clientset/versioned"
+	quotainformer "github.com/openshift/client-go/quota/informers/externalversions"
+	routeclient "github.com/openshift/client-go/route/clientset/versioned"
+	routeinformer "github.com/openshift/client-go/route/informers/externalversions"
+	securityclient "github.com/openshift/client-go/security/clientset/versioned"
+	securityinformer "github.com/openshift/client-go/security/informers/externalversions"
+	templateclient "github.com/openshift/client-go/template/clientset/versioned"
+	templateinformer "github.com/openshift/client-go/template/informers/externalversions"
+	userclient "github.com/openshift/client-go/user/clientset/versioned"
+	userinformer "github.com/openshift/client-go/user/informers/externalversions"
+)
+
+type externalKubeInformersWithExtraGenerics struct {
+	informers.SharedInformerFactory
+	genericResourceInformer GenericResourceInformer
+}
+
+func (i externalKubeInformersWithExtraGenerics) ForResource(resource schema.GroupVersionResource) (informers.GenericInformer, error) {
+	return i.genericResourceInformer.ForResource(resource)
+}
+
+func (i externalKubeInformersWithExtraGenerics) Start(stopCh <-chan struct{}) {
+	i.SharedInformerFactory.Start(stopCh)
+	i.genericResourceInformer.Start(stopCh)
+}
+
+type GenericResourceInformer interface {
+	ForResource(resource schema.GroupVersionResource) (informers.GenericInformer, error)
+	Start(stopCh <-chan struct{})
+}
+
+// genericResourceInformerFunc will handle a cast to a matching type
+type genericResourceInformerFunc func(resource schema.GroupVersionResource) (informers.GenericInformer, error)
+
+func (fn genericResourceInformerFunc) ForResource(resource schema.GroupVersionResource) (informers.GenericInformer, error) {
+	return fn(resource)
+}
+
+// this is a temporary condition until we rewrite enough of generation to auto-conform to the required interface and no longer need the internal version shim
+func (fn genericResourceInformerFunc) Start(stopCh <-chan struct{}) {}
+
+type genericInformers struct {
+	// this is a temporary condition until we rewrite enough of generation to auto-conform to the required interface and no longer need the internal version shim
+	startFn func(stopCh <-chan struct{})
+	generic []GenericResourceInformer
+}
+
+func newGenericInformers(startFn func(stopCh <-chan struct{}), informers ...GenericResourceInformer) genericInformers {
+	return genericInformers{
+		startFn: startFn,
+		generic: informers,
+	}
+}
+
+func (i genericInformers) ForResource(resource schema.GroupVersionResource) (informers.GenericInformer, error) {
+	var firstErr error
+	for _, generic := range i.generic {
+		informer, err := generic.ForResource(resource)
+		if err == nil {
+			return informer, nil
+		}
+		if firstErr == nil {
+			firstErr = err
+		}
+	}
+	klog.V(4).Infof("Couldn't find informer for %v", resource)
+	return nil, firstErr
+}
+
+func (i genericInformers) Start(stopCh <-chan struct{}) {
+	i.startFn(stopCh)
+	for _, generic := range i.generic {
+		generic.Start(stopCh)
+	}
+}
+
+// informers is a convenient way for us to keep track of the informers, but
+// is intentionally private.  We don't want to leak it out further than this package.
+// Everything else should say what it wants.
+type combinedInformers struct {
+	externalKubeInformers  informers.SharedInformerFactory
+	appInformers           appinformer.SharedInformerFactory
+	authorizationInformers authorizationinformer.SharedInformerFactory
+	buildInformers         buildinformer.SharedInformerFactory
+	imageInformers         imageinformer.SharedInformerFactory
+	networkInformers       networkinformer.SharedInformerFactory
+	oauthInformers         oauthinformer.SharedInformerFactory
+	quotaInformers         quotainformer.SharedInformerFactory
+	routeInformers         routeinformer.SharedInformerFactory
+	securityInformers      securityinformer.SharedInformerFactory
+	templateInformers      templateinformer.SharedInformerFactory
+	userInformers          userinformer.SharedInformerFactory
+}
+
+func newInformerFactory(clientConfig *rest.Config) (informers.SharedInformerFactory, error) {
+	kubeClient, err := kubernetes.NewForConfig(clientConfig)
+	if err != nil {
+		return nil, err
+	}
+	appClient, err := appclient.NewForConfig(clientConfig)
+	if err != nil {
+		return nil, err
+	}
+	authorizationClient, err := authorizationclient.NewForConfig(clientConfig)
+	if err != nil {
+		return nil, err
+	}
+	buildClient, err := buildclient.NewForConfig(clientConfig)
+	if err != nil {
+		return nil, err
+	}
+	imageClient, err := imageclient.NewForConfig(clientConfig)
+	if err != nil {
+		return nil, err
+	}
+	networkClient, err := networkclient.NewForConfig(clientConfig)
+	if err != nil {
+		return nil, err
+	}
+	oauthClient, err := oauthclient.NewForConfig(clientConfig)
+	if err != nil {
+		return nil, err
+	}
+	quotaClient, err := quotaclient.NewForConfig(clientConfig)
+	if err != nil {
+		return nil, err
+	}
+	routerClient, err := routeclient.NewForConfig(clientConfig)
+	if err != nil {
+		return nil, err
+	}
+	securityClient, err := securityclient.NewForConfig(clientConfig)
+	if err != nil {
+		return nil, err
+	}
+	templateClient, err := templateclient.NewForConfig(clientConfig)
+	if err != nil {
+		return nil, err
+	}
+	userClient, err := userclient.NewForConfig(clientConfig)
+	if err != nil {
+		return nil, err
+	}
+
+	// TODO find a single place to create and start informers.  During the 1.7 rebase this will come more naturally in a config object,
+	// before then we should try to eliminate our direct to storage access.  It's making us do weird things.
+	const defaultInformerResyncPeriod = 10 * time.Minute
+
+	trim := func(obj interface{}) (interface{}, error) {
+		if accessor, err := meta.Accessor(obj); err == nil {
+			accessor.SetManagedFields(nil)
+		}
+		return obj, nil
+	}
+
+	ci := &combinedInformers{
+		externalKubeInformers:  informers.NewSharedInformerFactoryWithOptions(kubeClient, defaultInformerResyncPeriod, informers.WithTransform(trim)),
+		appInformers:           appinformer.NewSharedInformerFactoryWithOptions(appClient, defaultInformerResyncPeriod, appinformer.WithTransform(trim)),
+		authorizationInformers: authorizationinformer.NewSharedInformerFactoryWithOptions(authorizationClient, defaultInformerResyncPeriod, authorizationinformer.WithTransform(trim)),
+		buildInformers:         buildinformer.NewSharedInformerFactoryWithOptions(buildClient, defaultInformerResyncPeriod, buildinformer.WithTransform(trim)),
+		imageInformers:         imageinformer.NewSharedInformerFactoryWithOptions(imageClient, defaultInformerResyncPeriod, imageinformer.WithTransform(trim)),
+		networkInformers:       networkinformer.NewSharedInformerFactoryWithOptions(networkClient, defaultInformerResyncPeriod, networkinformer.WithTransform(trim)),
+		oauthInformers:         oauthinformer.NewSharedInformerFactoryWithOptions(oauthClient, defaultInformerResyncPeriod, oauthinformer.WithTransform(trim)),
+		quotaInformers:         quotainformer.NewSharedInformerFactoryWithOptions(quotaClient, defaultInformerResyncPeriod, quotainformer.WithTransform(trim)),
+		routeInformers:         routeinformer.NewSharedInformerFactoryWithOptions(routerClient, defaultInformerResyncPeriod, routeinformer.WithTransform(trim)),
+		securityInformers:      securityinformer.NewSharedInformerFactoryWithOptions(securityClient, defaultInformerResyncPeriod, securityinformer.WithTransform(trim)),
+		templateInformers:      templateinformer.NewSharedInformerFactoryWithOptions(templateClient, defaultInformerResyncPeriod, templateinformer.WithTransform(trim)),
+		userInformers:          userinformer.NewSharedInformerFactoryWithOptions(userClient, defaultInformerResyncPeriod, userinformer.WithTransform(trim)),
+	}
+
+	return externalKubeInformersWithExtraGenerics{
+		SharedInformerFactory:   ci.GetExternalKubeInformers(),
+		genericResourceInformer: ci.ToGenericInformer(),
+	}, nil
+}
+
+func (i *combinedInformers) GetExternalKubeInformers() informers.SharedInformerFactory {
+	return i.externalKubeInformers
+}
+func (i *combinedInformers) GetAppInformers() appinformer.SharedInformerFactory {
+	return i.appInformers
+}
+func (i *combinedInformers) GetAuthorizationInformers() authorizationinformer.SharedInformerFactory {
+	return i.authorizationInformers
+}
+func (i *combinedInformers) GetBuildInformers() buildinformer.SharedInformerFactory {
+	return i.buildInformers
+}
+func (i *combinedInformers) GetImageInformers() imageinformer.SharedInformerFactory {
+	return i.imageInformers
+}
+func (i *combinedInformers) GetNetworkInformers() networkinformer.SharedInformerFactory {
+	return i.networkInformers
+}
+func (i *combinedInformers) GetOauthInformers() oauthinformer.SharedInformerFactory {
+	return i.oauthInformers
+}
+func (i *combinedInformers) GetQuotaInformers() quotainformer.SharedInformerFactory {
+	return i.quotaInformers
+}
+func (i *combinedInformers) GetRouteInformers() routeinformer.SharedInformerFactory {
+	return i.routeInformers
+}
+func (i *combinedInformers) GetSecurityInformers() securityinformer.SharedInformerFactory {
+	return i.securityInformers
+}
+func (i *combinedInformers) GetTemplateInformers() templateinformer.SharedInformerFactory {
+	return i.templateInformers
+}
+func (i *combinedInformers) GetUserInformers() userinformer.SharedInformerFactory {
+	return i.userInformers
+}
+
+// Start initializes all requested informers.
+func (i *combinedInformers) Start(stopCh <-chan struct{}) {
+	i.externalKubeInformers.Start(stopCh)
+	i.appInformers.Start(stopCh)
+	i.authorizationInformers.Start(stopCh)
+	i.buildInformers.Start(stopCh)
+	i.imageInformers.Start(stopCh)
+	i.networkInformers.Start(stopCh)
+	i.oauthInformers.Start(stopCh)
+	i.quotaInformers.Start(stopCh)
+	i.routeInformers.Start(stopCh)
+	i.securityInformers.Start(stopCh)
+	i.templateInformers.Start(stopCh)
+	i.userInformers.Start(stopCh)
+}
+
+func (i *combinedInformers) ToGenericInformer() GenericResourceInformer {
+	return newGenericInformers(
+		i.Start,
+		i.GetExternalKubeInformers(),
+		genericResourceInformerFunc(func(resource schema.GroupVersionResource) (informers.GenericInformer, error) {
+			return i.GetAppInformers().ForResource(resource)
+		}),
+		genericResourceInformerFunc(func(resource schema.GroupVersionResource) (informers.GenericInformer, error) {
+			return i.GetAuthorizationInformers().ForResource(resource)
+		}),
+		genericResourceInformerFunc(func(resource schema.GroupVersionResource) (informers.GenericInformer, error) {
+			return i.GetBuildInformers().ForResource(resource)
+		}),
+		genericResourceInformerFunc(func(resource schema.GroupVersionResource) (informers.GenericInformer, error) {
+			return i.GetImageInformers().ForResource(resource)
+		}),
+		genericResourceInformerFunc(func(resource schema.GroupVersionResource) (informers.GenericInformer, error) {
+			return i.GetNetworkInformers().ForResource(resource)
+		}),
+		genericResourceInformerFunc(func(resource schema.GroupVersionResource) (informers.GenericInformer, error) {
+			return i.GetOauthInformers().ForResource(resource)
+		}),
+		genericResourceInformerFunc(func(resource schema.GroupVersionResource) (informers.GenericInformer, error) {
+			return i.GetQuotaInformers().ForResource(resource)
+		}),
+		genericResourceInformerFunc(func(resource schema.GroupVersionResource) (informers.GenericInformer, error) {
+			return i.GetRouteInformers().ForResource(resource)
+		}),
+		genericResourceInformerFunc(func(resource schema.GroupVersionResource) (informers.GenericInformer, error) {
+			return i.GetSecurityInformers().ForResource(resource)
+		}),
+		genericResourceInformerFunc(func(resource schema.GroupVersionResource) (informers.GenericInformer, error) {
+			return i.GetTemplateInformers().ForResource(resource)
+		}),
+		genericResourceInformerFunc(func(resource schema.GroupVersionResource) (informers.GenericInformer, error) {
+			return i.GetUserInformers().ForResource(resource)
+		}),
+	)
+}
diff --git a/cmd/kube-controller-manager/app/patch_satoken.go b/cmd/kube-controller-manager/app/patch_satoken.go
new file mode 100644
index 00000000000..82f1bb9b3ff
--- /dev/null
+++ b/cmd/kube-controller-manager/app/patch_satoken.go
@@ -0,0 +1,87 @@
+package app
+
+import (
+	"fmt"
+	"io/ioutil"
+	"path/filepath"
+
+	certutil "k8s.io/client-go/util/cert"
+	serviceaccountcontroller "k8s.io/kubernetes/pkg/controller/serviceaccount"
+)
+
+var applyOpenShiftServiceServingCertCA = func(in serviceaccountcontroller.TokensControllerOptions) serviceaccountcontroller.TokensControllerOptions {
+	return in
+}
+
+func applyOpenShiftServiceServingCertCAFunc(openshiftConfigBase string, openshiftConfig map[string]interface{}) error {
+	serviceServingCertCAFilename := getServiceServingCertCAFilename(openshiftConfig)
+	if len(serviceServingCertCAFilename) == 0 {
+		return nil
+	}
+
+	resolvePath(&serviceServingCertCAFilename, openshiftConfigBase)
+
+	serviceServingCA, err := ioutil.ReadFile(serviceServingCertCAFilename)
+	if err != nil {
+		return fmt.Errorf("error reading ca file for Service Serving Certificate Signer: %s: %v", serviceServingCertCAFilename, err)
+	}
+	if _, err := certutil.ParseCertsPEM(serviceServingCA); err != nil {
+		return fmt.Errorf("error parsing ca file for Service Serving Certificate Signer: %s: %v", serviceServingCertCAFilename, err)
+	}
+
+	applyOpenShiftServiceServingCertCA = func(controllerOptions serviceaccountcontroller.TokensControllerOptions) serviceaccountcontroller.TokensControllerOptions {
+		if len(serviceServingCA) == 0 {
+			return controllerOptions
+		}
+
+		// if we have a rootCA bundle add that too.  The rootCA will be used when hitting the default master service, since those are signed
+		// using a different CA by default.  The rootCA's key is more closely guarded than ours and if it is compromised, that power could
+		// be used to change the trusted signers for every pod anyway, so we're already effectively trusting it.
+		if len(controllerOptions.RootCA) > 0 {
+			controllerOptions.ServiceServingCA = append(controllerOptions.ServiceServingCA, controllerOptions.RootCA...)
+			controllerOptions.ServiceServingCA = append(controllerOptions.ServiceServingCA, []byte("\n")...)
+		}
+		controllerOptions.ServiceServingCA = append(controllerOptions.ServiceServingCA, serviceServingCA...)
+
+		return controllerOptions
+	}
+
+	return nil
+}
+
+func getServiceServingCertCAFilename(config map[string]interface{}) string {
+	controllerConfig, ok := config["controllerConfig"]
+	if !ok {
+		sscConfig, ok := config["serviceServingCert"]
+		if !ok {
+			return ""
+		}
+		sscConfigMap := sscConfig.(map[string]interface{})
+		return sscConfigMap["certFile"].(string)
+	}
+	controllerConfigMap := controllerConfig.(map[string]interface{})
+	sscConfig, ok := controllerConfigMap["serviceServingCert"]
+	if !ok {
+		return ""
+	}
+	sscConfigMap := sscConfig.(map[string]interface{})
+	signerConfig, ok := sscConfigMap["signer"]
+	if !ok {
+		return ""
+	}
+	signerConfigMap := signerConfig.(map[string]interface{})
+	return signerConfigMap["certFile"].(string)
+}
+
+// resolvePath updates the given refs to be absolute paths, relative to the given base directory
+func resolvePath(ref *string, base string) error {
+	// Don't resolve empty paths
+	if len(*ref) > 0 {
+		// Don't resolve absolute paths
+		if !filepath.IsAbs(*ref) {
+			*ref = filepath.Join(base, *ref)
+		}
+	}
+
+	return nil
+}
diff --git a/pkg/controller/daemon/daemon_controller.go b/pkg/controller/daemon/daemon_controller.go
index 0076ca2411a..07cf0cb537e 100644
--- a/pkg/controller/daemon/daemon_controller.go
+++ b/pkg/controller/daemon/daemon_controller.go
@@ -120,7 +120,13 @@ type DaemonSetsController struct {
 	nodeLister corelisters.NodeLister
 	// nodeStoreSynced returns true if the node store has been synced at least once.
 	// Added as a member to the struct to allow injection for testing.
-	nodeStoreSynced cache.InformerSynced
+	nodeStoreSynced                    cache.InformerSynced
+	namespaceLister                    corelisters.NamespaceLister
+	namespaceStoreSynced               cache.InformerSynced
+	openshiftDefaultNodeSelectorString string
+	openshiftDefaultNodeSelector       labels.Selector
+	kubeDefaultNodeSelectorString      string
+	kubeDefaultNodeSelector            labels.Selector
 
 	// DaemonSet keys that need to be synced.
 	queue workqueue.TypedRateLimitingInterface[string]
@@ -297,6 +303,11 @@ func (dsc *DaemonSetsController) Run(ctx context.Context, workers int) {
 	if !cache.WaitForNamedCacheSync("daemon sets", ctx.Done(), dsc.podStoreSynced, dsc.nodeStoreSynced, dsc.historyStoreSynced, dsc.dsStoreSynced) {
 		return
 	}
+	if dsc.namespaceStoreSynced != nil {
+		if !cache.WaitForNamedCacheSync("daemon sets", ctx.Done(), dsc.namespaceStoreSynced) {
+			return
+		}
+	}
 
 	for i := 0; i < workers; i++ {
 		go wait.UntilWithContext(ctx, dsc.runWorker, time.Second)
@@ -651,7 +662,7 @@ func (dsc *DaemonSetsController) addNode(logger klog.Logger, obj interface{}) {
 	}
 	node := obj.(*v1.Node)
 	for _, ds := range dsList {
-		if shouldRun, _ := NodeShouldRunDaemonPod(node, ds); shouldRun {
+		if shouldRun, _ := dsc.nodeShouldRunDaemonPod(node, ds); shouldRun {
 			dsc.enqueueDaemonSet(ds)
 		}
 	}
@@ -678,9 +689,8 @@ func (dsc *DaemonSetsController) updateNode(logger klog.Logger, old, cur interfa
 	}
 	// TODO: it'd be nice to pass a hint with these enqueues, so that each ds would only examine the added node (unless it has other work to do, too).
 	for _, ds := range dsList {
-		// If NodeShouldRunDaemonPod needs to uses other than Labels and Taints (mutable) properties of node, it needs to update shouldIgnoreNodeUpdate.
-		oldShouldRun, oldShouldContinueRunning := NodeShouldRunDaemonPod(oldNode, ds)
-		currentShouldRun, currentShouldContinueRunning := NodeShouldRunDaemonPod(curNode, ds)
+		oldShouldRun, oldShouldContinueRunning := dsc.nodeShouldRunDaemonPod(oldNode, ds)
+		currentShouldRun, currentShouldContinueRunning := dsc.nodeShouldRunDaemonPod(curNode, ds)
 		if (oldShouldRun != currentShouldRun) || (oldShouldContinueRunning != currentShouldContinueRunning) {
 			dsc.enqueueDaemonSet(ds)
 		}
@@ -786,7 +796,7 @@ func (dsc *DaemonSetsController) podsShouldBeOnNode(
 	hash string,
 ) (nodesNeedingDaemonPods, podsToDelete []string) {
 
-	shouldRun, shouldContinueRunning := NodeShouldRunDaemonPod(node, ds)
+	shouldRun, shouldContinueRunning := dsc.nodeShouldRunDaemonPod(node, ds)
 	daemonPods, exists := nodeToDaemonPods[node.Name]
 
 	switch {
@@ -1141,7 +1151,7 @@ func (dsc *DaemonSetsController) updateDaemonSetStatus(ctx context.Context, ds *
 	var desiredNumberScheduled, currentNumberScheduled, numberMisscheduled, numberReady, updatedNumberScheduled, numberAvailable int
 	now := dsc.failedPodsBackoff.Clock.Now()
 	for _, node := range nodeList {
-		shouldRun, _ := NodeShouldRunDaemonPod(node, ds)
+		shouldRun, _ := dsc.nodeShouldRunDaemonPod(node, ds)
 		scheduled := len(nodeToDaemonPods[node.Name]) > 0
 
 		if shouldRun {
diff --git a/pkg/controller/daemon/patch_nodeselector.go b/pkg/controller/daemon/patch_nodeselector.go
new file mode 100644
index 00000000000..356437dd522
--- /dev/null
+++ b/pkg/controller/daemon/patch_nodeselector.go
@@ -0,0 +1,109 @@
+package daemon
+
+import (
+	"context"
+
+	appsv1 "k8s.io/api/apps/v1"
+	v1 "k8s.io/api/core/v1"
+	apierrors "k8s.io/apimachinery/pkg/api/errors"
+	"k8s.io/apimachinery/pkg/labels"
+	utilruntime "k8s.io/apimachinery/pkg/util/runtime"
+	appsinformers "k8s.io/client-go/informers/apps/v1"
+	coreinformers "k8s.io/client-go/informers/core/v1"
+	clientset "k8s.io/client-go/kubernetes"
+	"k8s.io/client-go/util/flowcontrol"
+
+	projectv1 "github.com/openshift/api/project/v1"
+)
+
+func NewNodeSelectorAwareDaemonSetsController(ctx context.Context, openshiftDefaultNodeSelectorString, kubeDefaultNodeSelectorString string, namepaceInformer coreinformers.NamespaceInformer, daemonSetInformer appsinformers.DaemonSetInformer, historyInformer appsinformers.ControllerRevisionInformer, podInformer coreinformers.PodInformer, nodeInformer coreinformers.NodeInformer, kubeClient clientset.Interface, failedPodsBackoff *flowcontrol.Backoff) (*DaemonSetsController, error) {
+	controller, err := NewDaemonSetsController(ctx, daemonSetInformer, historyInformer, podInformer, nodeInformer, kubeClient, failedPodsBackoff)
+
+	if err != nil {
+		return controller, err
+	}
+	controller.namespaceLister = namepaceInformer.Lister()
+	controller.namespaceStoreSynced = namepaceInformer.Informer().HasSynced
+	controller.openshiftDefaultNodeSelectorString = openshiftDefaultNodeSelectorString
+	if len(controller.openshiftDefaultNodeSelectorString) > 0 {
+		controller.openshiftDefaultNodeSelector, err = labels.Parse(controller.openshiftDefaultNodeSelectorString)
+		if err != nil {
+			return nil, err
+		}
+	}
+	controller.kubeDefaultNodeSelectorString = kubeDefaultNodeSelectorString
+	if len(controller.kubeDefaultNodeSelectorString) > 0 {
+		controller.kubeDefaultNodeSelector, err = labels.Parse(controller.kubeDefaultNodeSelectorString)
+		if err != nil {
+			return nil, err
+		}
+	}
+
+	return controller, nil
+}
+
+func (dsc *DaemonSetsController) nodeShouldRunDaemonPod(node *v1.Node, ds *appsv1.DaemonSet) (bool, bool) {
+	shouldRun, shouldContinueRunning := NodeShouldRunDaemonPod(node, ds)
+	if shouldRun && shouldContinueRunning {
+		if matches, matchErr := dsc.namespaceNodeSelectorMatches(node, ds); !matches || matchErr != nil {
+			return false, false
+		}
+	}
+
+	return shouldRun, shouldContinueRunning
+}
+
+func (dsc *DaemonSetsController) namespaceNodeSelectorMatches(node *v1.Node, ds *appsv1.DaemonSet) (bool, error) {
+	if dsc.namespaceLister == nil {
+		return true, nil
+	}
+
+	// this is racy (different listers) and we get to choose which way to fail.  This should requeue.
+	ns, err := dsc.namespaceLister.Get(ds.Namespace)
+	if apierrors.IsNotFound(err) {
+		return false, err
+	}
+	// if we had any error, default to the safe option of creating a pod for the node.
+	if err != nil {
+		utilruntime.HandleError(err)
+		return true, nil
+	}
+
+	return dsc.nodeSelectorMatches(node, ns), nil
+}
+
+func (dsc *DaemonSetsController) nodeSelectorMatches(node *v1.Node, ns *v1.Namespace) bool {
+	kubeNodeSelector, ok := ns.Annotations["scheduler.alpha.kubernetes.io/node-selector"]
+	if !ok {
+		originNodeSelector, ok := ns.Annotations[projectv1.ProjectNodeSelector]
+		switch {
+		case ok:
+			selector, err := labels.Parse(originNodeSelector)
+			if err == nil {
+				if !selector.Matches(labels.Set(node.Labels)) {
+					return false
+				}
+			}
+		case !ok && len(dsc.openshiftDefaultNodeSelectorString) > 0:
+			if !dsc.openshiftDefaultNodeSelector.Matches(labels.Set(node.Labels)) {
+				return false
+			}
+		}
+	}
+
+	switch {
+	case ok:
+		selector, err := labels.Parse(kubeNodeSelector)
+		if err == nil {
+			if !selector.Matches(labels.Set(node.Labels)) {
+				return false
+			}
+		}
+	case !ok && len(dsc.kubeDefaultNodeSelectorString) > 0:
+		if !dsc.kubeDefaultNodeSelector.Matches(labels.Set(node.Labels)) {
+			return false
+		}
+	}
+
+	return true
+}
diff --git a/pkg/controller/daemon/patch_nodeselector_test.go b/pkg/controller/daemon/patch_nodeselector_test.go
new file mode 100644
index 00000000000..6553fe694ea
--- /dev/null
+++ b/pkg/controller/daemon/patch_nodeselector_test.go
@@ -0,0 +1,186 @@
+package daemon
+
+import (
+	"testing"
+
+	projectv1 "github.com/openshift/api/project/v1"
+	"k8s.io/api/core/v1"
+	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
+	"k8s.io/apimachinery/pkg/labels"
+)
+
+func TestNamespaceNodeSelectorMatches(t *testing.T) {
+	nodes := []*v1.Node{
+		{
+			ObjectMeta: metav1.ObjectMeta{
+				Name: "first",
+				Labels: map[string]string{
+					"alpha": "bravo",
+				},
+			},
+		},
+		{
+			ObjectMeta: metav1.ObjectMeta{
+				Name: "second",
+				Labels: map[string]string{
+					"charlie": "delta",
+				},
+			},
+		},
+		{
+			ObjectMeta: metav1.ObjectMeta{
+				Name: "third",
+				Labels: map[string]string{
+					"echo": "foxtrot",
+				},
+			},
+		},
+		{
+			ObjectMeta: metav1.ObjectMeta{
+				Name:   "fourth",
+				Labels: map[string]string{},
+			},
+		},
+		{
+			ObjectMeta: metav1.ObjectMeta{
+				Name: "fifth",
+				Labels: map[string]string{
+					"charlie": "delta",
+					"echo":    "foxtrot",
+				},
+			},
+		},
+		{
+			ObjectMeta: metav1.ObjectMeta{
+				Name: "sixth",
+				Labels: map[string]string{
+					"alpha":   "bravo",
+					"charlie": "delta",
+					"echo":    "foxtrot",
+				},
+			},
+		},
+	}
+
+	pureDefault := &v1.Namespace{
+		ObjectMeta: metav1.ObjectMeta{},
+	}
+	all := &v1.Namespace{
+		ObjectMeta: metav1.ObjectMeta{
+			Annotations: map[string]string{
+				projectv1.ProjectNodeSelector: "",
+			},
+		},
+	}
+	projectSpecified := &v1.Namespace{
+		ObjectMeta: metav1.ObjectMeta{
+			Annotations: map[string]string{
+				projectv1.ProjectNodeSelector: "echo=foxtrot",
+			},
+		},
+	}
+	schedulerSpecified := &v1.Namespace{
+		ObjectMeta: metav1.ObjectMeta{
+			Annotations: map[string]string{
+				"scheduler.alpha.kubernetes.io/node-selector": "charlie=delta",
+			},
+		},
+	}
+	bothSpecified := &v1.Namespace{
+		ObjectMeta: metav1.ObjectMeta{
+			Annotations: map[string]string{
+				projectv1.ProjectNodeSelector:                 "echo=foxtrot",
+				"scheduler.alpha.kubernetes.io/node-selector": "charlie=delta",
+			},
+		},
+	}
+
+	tests := []struct {
+		name            string
+		defaultSelector string
+		namespace       *v1.Namespace
+		expected        map[string]bool
+	}{
+		{
+			name:            "pure-default",
+			defaultSelector: "alpha=bravo",
+			namespace:       pureDefault,
+			expected: map[string]bool{
+				"first": true,
+				"sixth": true,
+			},
+		},
+		{
+			name:            "all",
+			defaultSelector: "alpha=bravo",
+			namespace:       all,
+			expected: map[string]bool{
+				"first":  true,
+				"second": true,
+				"third":  true,
+				"fourth": true,
+				"fifth":  true,
+				"sixth":  true,
+			},
+		},
+		{
+			name:      "pure-default-without-default",
+			namespace: pureDefault,
+			expected: map[string]bool{
+				"first":  true,
+				"second": true,
+				"third":  true,
+				"fourth": true,
+				"fifth":  true,
+				"sixth":  true,
+			},
+		},
+		{
+			name:      "projectSpecified",
+			namespace: projectSpecified,
+			expected: map[string]bool{
+				"third": true,
+				"fifth": true,
+				"sixth": true,
+			},
+		},
+		{
+			name:      "schedulerSpecified",
+			namespace: schedulerSpecified,
+			expected: map[string]bool{
+				"second": true,
+				"fifth":  true,
+				"sixth":  true,
+			},
+		},
+		{
+			name:      "bothSpecified",
+			namespace: bothSpecified,
+			expected: map[string]bool{
+				"second": true,
+				"fifth":  true,
+				"sixth":  true,
+			},
+		},
+	}
+
+	for _, test := range tests {
+		t.Run(test.name, func(t *testing.T) {
+			c := &DaemonSetsController{}
+			c.openshiftDefaultNodeSelectorString = test.defaultSelector
+			if len(c.openshiftDefaultNodeSelectorString) > 0 {
+				var err error
+				c.openshiftDefaultNodeSelector, err = labels.Parse(c.openshiftDefaultNodeSelectorString)
+				if err != nil {
+					t.Fatal(err)
+				}
+			}
+
+			for _, node := range nodes {
+				if e, a := test.expected[node.Name], c.nodeSelectorMatches(node, test.namespace); e != a {
+					t.Errorf("%q expected %v, got %v", node.Name, e, a)
+				}
+			}
+		})
+	}
+}
-- 
2.47.0


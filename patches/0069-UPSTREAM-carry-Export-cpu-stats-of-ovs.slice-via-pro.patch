From b80bea63eac7415981339849ba58fcb7ad0e440e Mon Sep 17 00:00:00 2001
From: Martin Sivak <mars@montik.net>
Date: Thu, 31 Aug 2023 17:27:55 +0200
Subject: [PATCH] UPSTREAM: <carry>: Export cpu stats of ovs.slice via
 prometheus

When a PerformanceProfile configures a node for cpu partitioning,
it also lets OVS use all the cpus available to burstable pods.
To be able to do that, OVS was moved to its own slice and that
slice needs to be re-added to cAdvisor for monitoring purposes.
---
 cmd/kubelet/app/server.go | 6 ++++++
 1 file changed, 6 insertions(+)

diff --git a/cmd/kubelet/app/server.go b/cmd/kubelet/app/server.go
index 76e8cdf7b99..3a6599742c2 100644
--- a/cmd/kubelet/app/server.go
+++ b/cmd/kubelet/app/server.go
@@ -729,6 +729,12 @@ func run(ctx context.Context, s *options.KubeletServer, kubeDeps *kubelet.Depend
 		cgroupRoots = append(cgroupRoots, s.SystemCgroups)
 	}
 
+	// CARRY: Monitor extra cgroups that are specific to OpenShift deployments
+	//        Adding them here since there is no way to handle this via configuration atm
+	// - ovs.slice is configured on clusters that use the NTO's PerformanceProfile and only exists together
+	//   with system-cpu-reserved
+	cgroupRoots = append(cgroupRoots, "/ovs.slice")
+
 	if kubeDeps.CAdvisorInterface == nil {
 		imageFsInfoProvider := cadvisor.NewImageFsInfoProvider(s.ContainerRuntimeEndpoint)
 		kubeDeps.CAdvisorInterface, err = cadvisor.New(imageFsInfoProvider, s.RootDirectory, cgroupRoots, cadvisor.UsingLegacyCadvisorStats(s.ContainerRuntimeEndpoint), s.LocalStorageCapacityIsolation)
-- 
2.43.0

